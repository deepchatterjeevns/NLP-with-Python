{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_using_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/NLP-with-Python/blob/master/Deep_Learning_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiB1HT15j9it",
        "colab_type": "text"
      },
      "source": [
        "##Basic Perceptron Model\n",
        "\n",
        "Artificial neuron - Perceptron\n",
        "\n",
        "* weights for the input parameters start off as random initially\n",
        "\n",
        "* Activation Function :\n",
        "\n",
        "* Bias \n",
        "\n",
        "summation ( w(i) * x(i) + bias) where w(i) is the weight for each x(i)\n",
        "\n",
        "Bias is required in case the inputs to the neural network iiself is 0\n",
        "\n",
        "##Deep Neural Network:\n",
        "\n",
        "* Input Layer - Real Values from Data\n",
        "\n",
        "* Hidden Layers -Layers in between Input and Output Data. 3 or more layers is deep network\n",
        "\n",
        "* Output Layers - Final estimate of the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryZpsF8PmNmE",
        "colab_type": "text"
      },
      "source": [
        "##Activation Function \n",
        "\n",
        "**Z = WX + b**\n",
        "\n",
        "* Simple Output function 0 / 1\n",
        "\n",
        "* Sigmoid Function : f(Z) = 0 if Z< 0 \n",
        "                        = 1 if Z > 0\n",
        "                    1 /(1 + e ** -Z)\n",
        "\n",
        "* tanh(Z) hyperbolic tangent function : f(Z) = -1 if Z < 0\n",
        "                                             =  1 if Z >=0\n",
        "\n",
        "* RELU (Rectified Linear Unit) : f(Z) = max(0,Z)\n",
        "\n",
        "**RELU** tends to have best performance in many situations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUV4KIetmLPv",
        "colab_type": "text"
      },
      "source": [
        "## Keras Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEy7dd9Ifzg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOThXzzRozrd",
        "colab_type": "code",
        "outputId": "9580991e-91bf-4018-8d92-298d5250ec61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(iris)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN9g-9cho4bt",
        "colab_type": "code",
        "outputId": "af7044e2-a6e3-409b-e85f-92cad222db14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3UHwdo8o_5z",
        "colab_type": "code",
        "outputId": "54f9f6f8-8624-4f63-9d1f-c54f29587e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = iris.data\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_buBB9vpJQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgKayRGApNqF",
        "colab_type": "code",
        "outputId": "257b4d75-0d04-4210-bbb3-c9893a88dfe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRfYueYOpQoH",
        "colab_type": "code",
        "outputId": "50b12c92-88eb-4f55-a533-a0dbeea9fcc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFCenZvpSYn",
        "colab_type": "text"
      },
      "source": [
        "##Convert label into one hot encoding system using Keras builtin categorical function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjIcQ1V6pavT",
        "colab_type": "code",
        "outputId": "cf4a6482-cfa3-4bc3-bce6-636b08f28544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rhZYm0_p38A",
        "colab_type": "code",
        "outputId": "36197c58-7a15-4f84-d3f0-6ade841b2848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4nz2Jcp5_V",
        "colab_type": "text"
      },
      "source": [
        "##Split the data into training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWx9lzSNp-qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePbXQNczqZs9",
        "colab_type": "code",
        "outputId": "e05c163e-35cb-4573-f50a-80e2eafc7e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 4), (50, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtXIQf_uwKU",
        "colab_type": "text"
      },
      "source": [
        "##Normalize the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2wCKc-muzrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSGuDwIsvcXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgxClOhowPCL",
        "colab_type": "code",
        "outputId": "ffd8a834-7563-4a90-9b09-267cca31dee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_scaled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR9zcSl0wRut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnEbn-EpyGH7",
        "colab_type": "code",
        "outputId": "3de2c90b-20cc-43ab-a220-1377c9f1a063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8,input_dim=4,activation='relu'))\n",
        "model.add(Dense(8,input_dim=4,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0tS3Ymw1GZo",
        "colab_type": "code",
        "outputId": "380f9499-0cd1-4c7f-a6d9-b8e025d31a80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTwt8gb91Ouk",
        "colab_type": "code",
        "outputId": "20aac589-ca07-4156-f952-1f0a11768647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_scaled,y_train,epochs=150,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 1s - loss: 1.0901 - acc: 0.3100\n",
            "Epoch 2/150\n",
            " - 0s - loss: 1.0858 - acc: 0.3100\n",
            "Epoch 3/150\n",
            " - 0s - loss: 1.0820 - acc: 0.3100\n",
            "Epoch 4/150\n",
            " - 0s - loss: 1.0780 - acc: 0.3100\n",
            "Epoch 5/150\n",
            " - 0s - loss: 1.0740 - acc: 0.3200\n",
            "Epoch 6/150\n",
            " - 0s - loss: 1.0702 - acc: 0.3200\n",
            "Epoch 7/150\n",
            " - 0s - loss: 1.0662 - acc: 0.3200\n",
            "Epoch 8/150\n",
            " - 0s - loss: 1.0621 - acc: 0.3300\n",
            "Epoch 9/150\n",
            " - 0s - loss: 1.0576 - acc: 0.3500\n",
            "Epoch 10/150\n",
            " - 0s - loss: 1.0522 - acc: 0.3800\n",
            "Epoch 11/150\n",
            " - 0s - loss: 1.0468 - acc: 0.4100\n",
            "Epoch 12/150\n",
            " - 0s - loss: 1.0406 - acc: 0.4500\n",
            "Epoch 13/150\n",
            " - 0s - loss: 1.0344 - acc: 0.4900\n",
            "Epoch 14/150\n",
            " - 0s - loss: 1.0283 - acc: 0.5200\n",
            "Epoch 15/150\n",
            " - 0s - loss: 1.0217 - acc: 0.5600\n",
            "Epoch 16/150\n",
            " - 0s - loss: 1.0152 - acc: 0.5800\n",
            "Epoch 17/150\n",
            " - 0s - loss: 1.0089 - acc: 0.5800\n",
            "Epoch 18/150\n",
            " - 0s - loss: 1.0019 - acc: 0.5800\n",
            "Epoch 19/150\n",
            " - 0s - loss: 0.9948 - acc: 0.5800\n",
            "Epoch 20/150\n",
            " - 0s - loss: 0.9879 - acc: 0.5800\n",
            "Epoch 21/150\n",
            " - 0s - loss: 0.9817 - acc: 0.5800\n",
            "Epoch 22/150\n",
            " - 0s - loss: 0.9749 - acc: 0.5700\n",
            "Epoch 23/150\n",
            " - 0s - loss: 0.9681 - acc: 0.5700\n",
            "Epoch 24/150\n",
            " - 0s - loss: 0.9618 - acc: 0.5700\n",
            "Epoch 25/150\n",
            " - 0s - loss: 0.9556 - acc: 0.5700\n",
            "Epoch 26/150\n",
            " - 0s - loss: 0.9492 - acc: 0.6200\n",
            "Epoch 27/150\n",
            " - 0s - loss: 0.9430 - acc: 0.6500\n",
            "Epoch 28/150\n",
            " - 0s - loss: 0.9364 - acc: 0.6700\n",
            "Epoch 29/150\n",
            " - 0s - loss: 0.9303 - acc: 0.6900\n",
            "Epoch 30/150\n",
            " - 0s - loss: 0.9240 - acc: 0.7200\n",
            "Epoch 31/150\n",
            " - 0s - loss: 0.9175 - acc: 0.7500\n",
            "Epoch 32/150\n",
            " - 0s - loss: 0.9111 - acc: 0.7700\n",
            "Epoch 33/150\n",
            " - 0s - loss: 0.9046 - acc: 0.7700\n",
            "Epoch 34/150\n",
            " - 0s - loss: 0.8978 - acc: 0.7400\n",
            "Epoch 35/150\n",
            " - 0s - loss: 0.8911 - acc: 0.7200\n",
            "Epoch 36/150\n",
            " - 0s - loss: 0.8844 - acc: 0.7200\n",
            "Epoch 37/150\n",
            " - 0s - loss: 0.8773 - acc: 0.7600\n",
            "Epoch 38/150\n",
            " - 0s - loss: 0.8706 - acc: 0.7700\n",
            "Epoch 39/150\n",
            " - 0s - loss: 0.8635 - acc: 0.7700\n",
            "Epoch 40/150\n",
            " - 0s - loss: 0.8558 - acc: 0.7600\n",
            "Epoch 41/150\n",
            " - 0s - loss: 0.8490 - acc: 0.7600\n",
            "Epoch 42/150\n",
            " - 0s - loss: 0.8423 - acc: 0.7500\n",
            "Epoch 43/150\n",
            " - 0s - loss: 0.8357 - acc: 0.7600\n",
            "Epoch 44/150\n",
            " - 0s - loss: 0.8289 - acc: 0.7900\n",
            "Epoch 45/150\n",
            " - 0s - loss: 0.8225 - acc: 0.8100\n",
            "Epoch 46/150\n",
            " - 0s - loss: 0.8160 - acc: 0.7900\n",
            "Epoch 47/150\n",
            " - 0s - loss: 0.8096 - acc: 0.7800\n",
            "Epoch 48/150\n",
            " - 0s - loss: 0.8032 - acc: 0.8000\n",
            "Epoch 49/150\n",
            " - 0s - loss: 0.7970 - acc: 0.8000\n",
            "Epoch 50/150\n",
            " - 0s - loss: 0.7907 - acc: 0.7900\n",
            "Epoch 51/150\n",
            " - 0s - loss: 0.7848 - acc: 0.8000\n",
            "Epoch 52/150\n",
            " - 0s - loss: 0.7789 - acc: 0.7900\n",
            "Epoch 53/150\n",
            " - 0s - loss: 0.7730 - acc: 0.8000\n",
            "Epoch 54/150\n",
            " - 0s - loss: 0.7670 - acc: 0.8000\n",
            "Epoch 55/150\n",
            " - 0s - loss: 0.7615 - acc: 0.8000\n",
            "Epoch 56/150\n",
            " - 0s - loss: 0.7560 - acc: 0.7900\n",
            "Epoch 57/150\n",
            " - 0s - loss: 0.7501 - acc: 0.8000\n",
            "Epoch 58/150\n",
            " - 0s - loss: 0.7447 - acc: 0.7800\n",
            "Epoch 59/150\n",
            " - 0s - loss: 0.7393 - acc: 0.7900\n",
            "Epoch 60/150\n",
            " - 0s - loss: 0.7340 - acc: 0.7900\n",
            "Epoch 61/150\n",
            " - 0s - loss: 0.7288 - acc: 0.8000\n",
            "Epoch 62/150\n",
            " - 0s - loss: 0.7235 - acc: 0.8100\n",
            "Epoch 63/150\n",
            " - 0s - loss: 0.7184 - acc: 0.8200\n",
            "Epoch 64/150\n",
            " - 0s - loss: 0.7135 - acc: 0.8200\n",
            "Epoch 65/150\n",
            " - 0s - loss: 0.7087 - acc: 0.8200\n",
            "Epoch 66/150\n",
            " - 0s - loss: 0.7040 - acc: 0.8100\n",
            "Epoch 67/150\n",
            " - 0s - loss: 0.6993 - acc: 0.8200\n",
            "Epoch 68/150\n",
            " - 0s - loss: 0.6947 - acc: 0.8200\n",
            "Epoch 69/150\n",
            " - 0s - loss: 0.6904 - acc: 0.8100\n",
            "Epoch 70/150\n",
            " - 0s - loss: 0.6857 - acc: 0.8200\n",
            "Epoch 71/150\n",
            " - 0s - loss: 0.6813 - acc: 0.8300\n",
            "Epoch 72/150\n",
            " - 0s - loss: 0.6769 - acc: 0.8300\n",
            "Epoch 73/150\n",
            " - 0s - loss: 0.6726 - acc: 0.8400\n",
            "Epoch 74/150\n",
            " - 0s - loss: 0.6684 - acc: 0.8400\n",
            "Epoch 75/150\n",
            " - 0s - loss: 0.6640 - acc: 0.8400\n",
            "Epoch 76/150\n",
            " - 0s - loss: 0.6598 - acc: 0.8400\n",
            "Epoch 77/150\n",
            " - 0s - loss: 0.6555 - acc: 0.8300\n",
            "Epoch 78/150\n",
            " - 0s - loss: 0.6514 - acc: 0.8300\n",
            "Epoch 79/150\n",
            " - 0s - loss: 0.6474 - acc: 0.8100\n",
            "Epoch 80/150\n",
            " - 0s - loss: 0.6433 - acc: 0.8100\n",
            "Epoch 81/150\n",
            " - 0s - loss: 0.6392 - acc: 0.8100\n",
            "Epoch 82/150\n",
            " - 0s - loss: 0.6352 - acc: 0.8000\n",
            "Epoch 83/150\n",
            " - 0s - loss: 0.6312 - acc: 0.8200\n",
            "Epoch 84/150\n",
            " - 0s - loss: 0.6272 - acc: 0.8200\n",
            "Epoch 85/150\n",
            " - 0s - loss: 0.6235 - acc: 0.8300\n",
            "Epoch 86/150\n",
            " - 0s - loss: 0.6198 - acc: 0.8400\n",
            "Epoch 87/150\n",
            " - 0s - loss: 0.6161 - acc: 0.8600\n",
            "Epoch 88/150\n",
            " - 0s - loss: 0.6122 - acc: 0.8500\n",
            "Epoch 89/150\n",
            " - 0s - loss: 0.6083 - acc: 0.8500\n",
            "Epoch 90/150\n",
            " - 0s - loss: 0.6046 - acc: 0.8400\n",
            "Epoch 91/150\n",
            " - 0s - loss: 0.6008 - acc: 0.8400\n",
            "Epoch 92/150\n",
            " - 0s - loss: 0.5971 - acc: 0.8400\n",
            "Epoch 93/150\n",
            " - 0s - loss: 0.5935 - acc: 0.8400\n",
            "Epoch 94/150\n",
            " - 0s - loss: 0.5898 - acc: 0.8300\n",
            "Epoch 95/150\n",
            " - 0s - loss: 0.5859 - acc: 0.8100\n",
            "Epoch 96/150\n",
            " - 0s - loss: 0.5827 - acc: 0.8100\n",
            "Epoch 97/150\n",
            " - 0s - loss: 0.5786 - acc: 0.8100\n",
            "Epoch 98/150\n",
            " - 0s - loss: 0.5752 - acc: 0.8000\n",
            "Epoch 99/150\n",
            " - 0s - loss: 0.5712 - acc: 0.8000\n",
            "Epoch 100/150\n",
            " - 0s - loss: 0.5674 - acc: 0.8000\n",
            "Epoch 101/150\n",
            " - 0s - loss: 0.5638 - acc: 0.8100\n",
            "Epoch 102/150\n",
            " - 0s - loss: 0.5601 - acc: 0.8100\n",
            "Epoch 103/150\n",
            " - 0s - loss: 0.5562 - acc: 0.8300\n",
            "Epoch 104/150\n",
            " - 0s - loss: 0.5524 - acc: 0.8600\n",
            "Epoch 105/150\n",
            " - 0s - loss: 0.5486 - acc: 0.8800\n",
            "Epoch 106/150\n",
            " - 0s - loss: 0.5448 - acc: 0.8800\n",
            "Epoch 107/150\n",
            " - 0s - loss: 0.5411 - acc: 0.8900\n",
            "Epoch 108/150\n",
            " - 0s - loss: 0.5374 - acc: 0.8900\n",
            "Epoch 109/150\n",
            " - 0s - loss: 0.5338 - acc: 0.8800\n",
            "Epoch 110/150\n",
            " - 0s - loss: 0.5303 - acc: 0.8800\n",
            "Epoch 111/150\n",
            " - 0s - loss: 0.5265 - acc: 0.9000\n",
            "Epoch 112/150\n",
            " - 0s - loss: 0.5227 - acc: 0.8900\n",
            "Epoch 113/150\n",
            " - 0s - loss: 0.5190 - acc: 0.8800\n",
            "Epoch 114/150\n",
            " - 0s - loss: 0.5152 - acc: 0.8900\n",
            "Epoch 115/150\n",
            " - 0s - loss: 0.5114 - acc: 0.8900\n",
            "Epoch 116/150\n",
            " - 0s - loss: 0.5074 - acc: 0.9000\n",
            "Epoch 117/150\n",
            " - 0s - loss: 0.5038 - acc: 0.9100\n",
            "Epoch 118/150\n",
            " - 0s - loss: 0.5005 - acc: 0.9200\n",
            "Epoch 119/150\n",
            " - 0s - loss: 0.4969 - acc: 0.9200\n",
            "Epoch 120/150\n",
            " - 0s - loss: 0.4936 - acc: 0.9300\n",
            "Epoch 121/150\n",
            " - 0s - loss: 0.4902 - acc: 0.9300\n",
            "Epoch 122/150\n",
            " - 0s - loss: 0.4864 - acc: 0.9200\n",
            "Epoch 123/150\n",
            " - 0s - loss: 0.4832 - acc: 0.9200\n",
            "Epoch 124/150\n",
            " - 0s - loss: 0.4799 - acc: 0.9200\n",
            "Epoch 125/150\n",
            " - 0s - loss: 0.4763 - acc: 0.9300\n",
            "Epoch 126/150\n",
            " - 0s - loss: 0.4729 - acc: 0.9300\n",
            "Epoch 127/150\n",
            " - 0s - loss: 0.4696 - acc: 0.9300\n",
            "Epoch 128/150\n",
            " - 0s - loss: 0.4665 - acc: 0.9200\n",
            "Epoch 129/150\n",
            " - 0s - loss: 0.4626 - acc: 0.9300\n",
            "Epoch 130/150\n",
            " - 0s - loss: 0.4592 - acc: 0.9300\n",
            "Epoch 131/150\n",
            " - 0s - loss: 0.4556 - acc: 0.9300\n",
            "Epoch 132/150\n",
            " - 0s - loss: 0.4522 - acc: 0.9400\n",
            "Epoch 133/150\n",
            " - 0s - loss: 0.4489 - acc: 0.9700\n",
            "Epoch 134/150\n",
            " - 0s - loss: 0.4465 - acc: 0.9600\n",
            "Epoch 135/150\n",
            " - 0s - loss: 0.4438 - acc: 0.9800\n",
            "Epoch 136/150\n",
            " - 0s - loss: 0.4409 - acc: 0.9800\n",
            "Epoch 137/150\n",
            " - 0s - loss: 0.4370 - acc: 0.9700\n",
            "Epoch 138/150\n",
            " - 0s - loss: 0.4325 - acc: 0.9600\n",
            "Epoch 139/150\n",
            " - 0s - loss: 0.4284 - acc: 0.9700\n",
            "Epoch 140/150\n",
            " - 0s - loss: 0.4248 - acc: 0.9700\n",
            "Epoch 141/150\n",
            " - 0s - loss: 0.4212 - acc: 0.9700\n",
            "Epoch 142/150\n",
            " - 0s - loss: 0.4180 - acc: 0.9700\n",
            "Epoch 143/150\n",
            " - 0s - loss: 0.4143 - acc: 0.9700\n",
            "Epoch 144/150\n",
            " - 0s - loss: 0.4111 - acc: 0.9700\n",
            "Epoch 145/150\n",
            " - 0s - loss: 0.4074 - acc: 0.9700\n",
            "Epoch 146/150\n",
            " - 0s - loss: 0.4042 - acc: 0.9700\n",
            "Epoch 147/150\n",
            " - 0s - loss: 0.4017 - acc: 0.9700\n",
            "Epoch 148/150\n",
            " - 0s - loss: 0.3982 - acc: 0.9600\n",
            "Epoch 149/150\n",
            " - 0s - loss: 0.3953 - acc: 0.9700\n",
            "Epoch 150/150\n",
            " - 0s - loss: 0.3926 - acc: 0.9700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88cadc00b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmKyilQ51fzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X_test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq-NX_Yv1-S-",
        "colab_type": "code",
        "outputId": "d42a5ff2-35ea-426f-8ed8-b857c3a9dacc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 1, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SErErxe2BKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = y_test.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZXnckF62JCL",
        "colab_type": "code",
        "outputId": "2a09b33e-a3e2-4447-f343-a173cb47ee3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       0.94      1.00      0.97        15\n",
            "           2       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.98      0.98      0.98        50\n",
            "weighted avg       0.98      0.98      0.98        50\n",
            "\n",
            "[[19  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 15]]\n",
            "0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOSjVfX02HhI",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4VMdu_b21Kc",
        "colab_type": "code",
        "outputId": "83a449e2-0990-4202-825e-5d736d9b1bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.distplot(y_test,hist=False,label='Actual Label',color='b')\n",
        "sns.distplot(y_pred,hist=False,label='Predicted Label',color='r')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f88701058d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAStoltl3jHi",
        "colab_type": "text"
      },
      "source": [
        "##Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOWwC3lm3lvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('FirstKearsmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2JyS5j13xje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "my_new_model = load_model('FirstKearsmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jmc_Ky54Y0R",
        "colab_type": "text"
      },
      "source": [
        "##Predict on new unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4l70k784Nwl",
        "colab_type": "code",
        "outputId": "129b93bf-1fc5-401d-b537-3c9f1ed28730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_new_model.predict_classes(X_train_scaled)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0,\n",
              "       2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2,\n",
              "       2, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2,\n",
              "       1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 1, 0, 2, 0, 1, 2, 2,\n",
              "       1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOaDJHo34ckm",
        "colab_type": "text"
      },
      "source": [
        "##Recurrent Neural Network\n",
        "\n",
        "Specifically designed to work with sequence data\n",
        "\n",
        "* Normal feed forward network :\n",
        "input --> aggregation --> activation function ---> output\n",
        "\n",
        "* Recurrent Neural Network :\n",
        "input --> aggregation --> activation function ---> output ---> feed back to input\n",
        "\n",
        "* Cells that are a function of inputs from previous time steps are known as memory cells\n",
        "\n",
        "* RNN are also flexible in their inputs and outputs for both sequences and single vector values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2tNRYWbBHt4",
        "colab_type": "text"
      },
      "source": [
        "## LSTMs GRU  and Text Generation\n",
        "\n",
        "* The issue with RNN is that after a while the network will begin to forget the first input as information is lost at each step  going through the RNN.\n",
        "\n",
        "The LSTM(Long Term Short Term Memory) helps to address the above issue.\n",
        "\n",
        "\n",
        "## Text Generation with LSTM using KERAS\n",
        "\n",
        "* Process Text\n",
        "* Clean Text\n",
        "* Tokenize the Text and create Sequences with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAEO80pU4fdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_files(filepath):\n",
        "  with open(filepath,'r') as f:\n",
        "    str_text = f.read()\n",
        "  return str_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNm5ajeJG7dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " text = read_files('/content/moby_dick_four_chapters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhQZ0E3NHGeH",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize and Clean the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgSunjvcHKQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en',disable=['parser','tagger','ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-kQv7U6HzXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp.max_length = 1198623"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mqOkcmaI8RH",
        "colab_type": "text"
      },
      "source": [
        "## Separate Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNgcgSECI70e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "punc_set = list(string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz177UP3KRDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punc_list = punc_set + [\"\\n\",\"\\n\\n\",\"\\n\\n\\n\",\"--\",\"\\t\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrbDKyS7L8e3",
        "colab_type": "code",
        "outputId": "c7e4eae9-8fb7-41e1-ecaa-5018fb98c524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "punc_list"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " '\\n',\n",
              " '\\n\\n',\n",
              " '\\n\\n\\n',\n",
              " '--',\n",
              " '\\t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuvH3z0QKcGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sep_punc(doc_text):\n",
        "  return [token.text.lower() for token in nlp(doc_text) if token.text not in punc_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVG0PqphLLHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = read_files('/content/moby_dick_four_chapters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6EsOC5kLZdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = sep_punc(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbMxesfcLlqS",
        "colab_type": "code",
        "outputId": "fa69f629-b883-493c-946e-2b0c2df6d810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvi2GiRZMtP2",
        "colab_type": "text"
      },
      "source": [
        "##Create Sequence of Tokens\n",
        "\n",
        "i.e. pass fisrt 24 words of the sequence to the model and predict the 25th word in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84QjznnvM-jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize into sequence of tokens\n",
        "train_len = 25 + 1 # 25 training words , then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len,len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN5iciVxQX4g",
        "colab_type": "code",
        "outputId": "afc20575-982a-412c-9b74-06352627b73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "text_sequences[0]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call',\n",
              " 'me',\n",
              " 'ishmael',\n",
              " ' ',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and',\n",
              " 'nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeuvsDPSQeI2",
        "colab_type": "code",
        "outputId": "39364c45-f91d-4c53-9a84-4b9a1dec4ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "text_sequences[1]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['me',\n",
              " 'ishmael',\n",
              " ' ',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and',\n",
              " 'nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me',\n",
              " 'on']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqsz9h2aQnCl",
        "colab_type": "code",
        "outputId": "cbe450d2-a448-44ef-b206-f14df907cdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael   some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and see the watery part of the world   it is a way i have'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7HOSoeQRNrp",
        "colab_type": "code",
        "outputId": "87b1361e-bb69-4c77-e0b6-b28c5893f79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl_sIJw5Qw9A",
        "colab_type": "code",
        "outputId": "706d8689-745c-4d8e-a1c3-d9d7469f2525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me ishmael   some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-4P9tXORF12",
        "colab_type": "code",
        "outputId": "97ed9334-ccfb-4975-86a6-5e6b22e41bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ishmael   some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "142NUn_MSG92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEsYgDcnT4tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lQFDyYUd_Y",
        "colab_type": "code",
        "outputId": "27a8f826-9bb7-41fe-c8cc-f712cd927ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
        "sequences[0]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[956,\n",
              " 15,\n",
              " 263,\n",
              " 4,\n",
              " 52,\n",
              " 261,\n",
              " 408,\n",
              " 88,\n",
              " 219,\n",
              " 130,\n",
              " 112,\n",
              " 954,\n",
              " 260,\n",
              " 51,\n",
              " 44,\n",
              " 39,\n",
              " 315,\n",
              " 8,\n",
              " 24,\n",
              " 546,\n",
              " 3,\n",
              " 150,\n",
              " 259,\n",
              " 7,\n",
              " 2711,\n",
              " 15]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwbRIomMU_oZ",
        "colab_type": "code",
        "outputId": "7dd85350-8989-4ccb-e885-523472413016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "for i in sequences[0]:\n",
        "  print(f\"{i}:{tokenizer.index_word[i]}\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "956:call\n",
            "15:me\n",
            "263:ishmael\n",
            "4: \n",
            "52:some\n",
            "261:years\n",
            "408:ago\n",
            "88:never\n",
            "219:mind\n",
            "130:how\n",
            "112:long\n",
            "954:precisely\n",
            "260:having\n",
            "51:little\n",
            "44:or\n",
            "39:no\n",
            "315:money\n",
            "8:in\n",
            "24:my\n",
            "546:purse\n",
            "3:and\n",
            "150:nothing\n",
            "259:particular\n",
            "7:to\n",
            "2711:interest\n",
            "15:me\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3jmheZ-YKtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f757e8c-31f2-4b57-8c25-1af9f4219ecf"
      },
      "source": [
        "len(tokenizer.word_counts)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlWcMA2lYqk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHDU5maCY02n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0515d4e2-400e-456a-9268-5299aade6bfc"
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGAPwMDyY8kj",
        "colab_type": "text"
      },
      "source": [
        "## Convert the text sequences into a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzk0nV0qZDAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "sequences = np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtKILhHjZNkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5401ea17-6a3c-4cc1-d51e-89797ef0fc01"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   15,  263, ...,    7, 2711,   15],\n",
              "       [  15,  263,    4, ..., 2711,   15,   25],\n",
              "       [ 263,    4,   52, ...,   15,   25,  957],\n",
              "       ...,\n",
              "       [ 952,   13,  166, ...,  262,   54,    2],\n",
              "       [  13,  166, 2712, ...,   54,    2, 2717],\n",
              "       [ 166, 2712,    3, ...,    2, 2717,   27]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9OuIUafZZhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "489fe77f-a6d3-4446-c398-8eabd1717402"
      },
      "source": [
        "sequences.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11627, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSkxTsRUZdnh",
        "colab_type": "text"
      },
      "source": [
        "#### label is the 51st column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOEIKOWrQgn",
        "colab_type": "text"
      },
      "source": [
        "##Split the data into features and labels\n",
        "\n",
        "X = First n words of Sequence\n",
        "\n",
        "Y = Next word after Sequence (Label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXlncvQAZhLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1c0ad27c-9b10-48fd-ee5f-851a8de152bd"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "sequences[:,:-1]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   15,  263, ...,  259,    7, 2711],\n",
              "       [  15,  263,    4, ...,    7, 2711,   15],\n",
              "       [ 263,    4,   52, ..., 2711,   15,   25],\n",
              "       ...,\n",
              "       [ 952,   13,  166, ...,   12,  262,   54],\n",
              "       [  13,  166, 2712, ...,  262,   54,    2],\n",
              "       [ 166, 2712,    3, ...,   54,    2, 2717]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqYrOetesAMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = sequences[:,:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npopXwjCr58U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = sequences[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_0yno6lsW4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1gnQsFGsFf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = to_categorical(Y,num_classes=vocabulary_size + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL809bjEtNOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38ab2192-93a7-4222-b3fc-ecf30e6749cf"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11627, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcSve2ButG-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQYndZ-8rnEV",
        "colab_type": "text"
      },
      "source": [
        "##Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwj6CVGAtZ2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqmMT0UntkF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocabulary_size,seq_len):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocabulary_size,output_dim=seq_len,input_length=seq_len))\n",
        "  model.add(LSTM(units=seq_len**2,return_sequences=True))\n",
        "  model.add(LSTM(units=150))\n",
        "  model.add(Dense(150,activation='relu'))\n",
        "  model.add(Dense(vocabulary_size,activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKlrZUq-vL_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "21527b80-b28b-49af-f21b-2a9632bfc54f"
      },
      "source": [
        "lstm_model = create_model(vocabulary_size + 1,seq_len)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 50)            135900    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 50, 2500)          25510000  \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 150)               1590600   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 150)               22650     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2718)              410418    \n",
            "=================================================================\n",
            "Total params: 27,669,568\n",
            "Trainable params: 27,669,568\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsbf5jj0v89H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBbTSaVcrpNK",
        "colab_type": "text"
      },
      "source": [
        "##Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQRL-SVnwBpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "8c5513d6-b54a-4e45-a659-a82da27c8cc7"
      },
      "source": [
        "lstm_model.fit(X,Y,batch_size=128,epochs=3,verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "11602/11602 [==============================] - 50s 4ms/step - loss: 6.7525 - acc: 0.0475\n",
            "Epoch 2/3\n",
            "11602/11602 [==============================] - 30s 3ms/step - loss: 6.3330 - acc: 0.0514\n",
            "Epoch 3/3\n",
            "11602/11602 [==============================] - 30s 3ms/step - loss: 6.3163 - acc: 0.0514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faadf4c3b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p_a2nD8yJBC",
        "colab_type": "text"
      },
      "source": [
        "## Train atleast fr 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkTs7tcSyMbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_model.save('lstmmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6MrGjtLyawI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(tokenizer,open('lstmtokenizer','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIrs29_8ysHj",
        "colab_type": "text"
      },
      "source": [
        "##Genearte new text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT73yEh-zs-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HggIYm4Zyucg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model,tokenizer,seq_len,seed_text,num_gen_words):#seed_text = sample text\n",
        "  output_text = []\n",
        "  input_text = seed_text\n",
        "  for i in range(num_gen_words):\n",
        "    encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    pad_encoded = pad_sequences([encoded_text],maxlen=seq_len,truncating='pre') #pad sequences to same length\n",
        "    pred_word_index = model.predict_classes(pad_encoded,verbose=0)[0]\n",
        "    pred_word = tokenizer.index_word[pred_word_index]\n",
        "\n",
        "    input_text = input_text + \" \" + pred_word\n",
        "    output_text.append(pred_word)\n",
        "  return ' '.join(output_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQf-xOH51Vjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "seq = random.randint(0,len(text_sequences))\n",
        "seed_text = \" \".join(text_sequences[seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GUvU-sJ2Qwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b61af93-793e-4ac2-c090-2ab6d299e7b3"
      },
      "source": [
        "seed_text "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'with halting steps i paced the streets and passed the sign of the crossed harpoons\"--but it looked too expensive and jolly there further on from the bright red windows of the sword fish inn there came such fervent rays that it seemed to have melted the packed snow and ice from'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYz6C4qc1uKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next_words = generate_text(lstm_model,tokenizer,seq_len,seed_text,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw4c-NEd2yjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4fbc871-4ad2-4431-eb95-726ed6d8af27"
      },
      "source": [
        "next_words"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the the the the the the the the the the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjEjUoQ83a2P",
        "colab_type": "text"
      },
      "source": [
        "##Load Pretrained Model trained with 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4gwbEt33fGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/epochBIG.h5')\n",
        "tokenizer = load(open('/content/epochBIG','rb'))\n",
        "\n",
        "next_words = generate_text(model,tokenizer,seq_len,seed_text,25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zaii7TwK6FkS",
        "colab_type": "text"
      },
      "source": [
        "## The next sent of 25 words predicted by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sdGg72d6A7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f7fb9cc4-4874-4665-fd80-03d4aafbf7a4"
      },
      "source": [
        "next_words"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'twenty primary four or more honourable plight and at the slightest sullen sun to pick town the soot of old land smote a perilous wondrous'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    }
  ]
}