{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_using_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/NLP-with-Python/blob/master/Deep_Learning_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiB1HT15j9it",
        "colab_type": "text"
      },
      "source": [
        "##Basic Perceptron Model\n",
        "\n",
        "Artificial neuron - Perceptron\n",
        "\n",
        "* weights for the input parameters start off as random initially\n",
        "\n",
        "* Activation Function :\n",
        "\n",
        "* Bias \n",
        "\n",
        "summation ( w(i) * x(i) + bias) where w(i) is the weight for each x(i)\n",
        "\n",
        "Bias is required in case the inputs to the neural network iiself is 0\n",
        "\n",
        "##Deep Neural Network:\n",
        "\n",
        "* Input Layer - Real Values from Data\n",
        "\n",
        "* Hidden Layers -Layers in between Input and Output Data. 3 or more layers is deep network\n",
        "\n",
        "* Output Layers - Final estimate of the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryZpsF8PmNmE",
        "colab_type": "text"
      },
      "source": [
        "##Activation Function \n",
        "\n",
        "**Z = WX + b**\n",
        "\n",
        "* Simple Output function 0 / 1\n",
        "\n",
        "* Sigmoid Function : f(Z) = 0 if Z< 0 \n",
        "                        = 1 if Z > 0\n",
        "                    1 /(1 + e ** -Z)\n",
        "\n",
        "* tanh(Z) hyperbolic tangent function : f(Z) = -1 if Z < 0\n",
        "                                             =  1 if Z >=0\n",
        "\n",
        "* RELU (Rectified Linear Unit) : f(Z) = max(0,Z)\n",
        "\n",
        "**RELU** tends to have best performance in many situations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUV4KIetmLPv",
        "colab_type": "text"
      },
      "source": [
        "## Keras Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEy7dd9Ifzg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOThXzzRozrd",
        "colab_type": "code",
        "outputId": "9580991e-91bf-4018-8d92-298d5250ec61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(iris)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN9g-9cho4bt",
        "colab_type": "code",
        "outputId": "af7044e2-a6e3-409b-e85f-92cad222db14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3UHwdo8o_5z",
        "colab_type": "code",
        "outputId": "54f9f6f8-8624-4f63-9d1f-c54f29587e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = iris.data\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_buBB9vpJQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgKayRGApNqF",
        "colab_type": "code",
        "outputId": "257b4d75-0d04-4210-bbb3-c9893a88dfe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRfYueYOpQoH",
        "colab_type": "code",
        "outputId": "50b12c92-88eb-4f55-a533-a0dbeea9fcc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFCenZvpSYn",
        "colab_type": "text"
      },
      "source": [
        "##Convert label into one hot encoding system using Keras builtin categorical function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjIcQ1V6pavT",
        "colab_type": "code",
        "outputId": "cf4a6482-cfa3-4bc3-bce6-636b08f28544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rhZYm0_p38A",
        "colab_type": "code",
        "outputId": "36197c58-7a15-4f84-d3f0-6ade841b2848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4nz2Jcp5_V",
        "colab_type": "text"
      },
      "source": [
        "##Split the data into training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWx9lzSNp-qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePbXQNczqZs9",
        "colab_type": "code",
        "outputId": "e05c163e-35cb-4573-f50a-80e2eafc7e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 4), (50, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtXIQf_uwKU",
        "colab_type": "text"
      },
      "source": [
        "##Normalize the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2wCKc-muzrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSGuDwIsvcXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgxClOhowPCL",
        "colab_type": "code",
        "outputId": "ffd8a834-7563-4a90-9b09-267cca31dee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_scaled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n",
              "       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n",
              "       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n",
              "       [1.        , 0.36363636, 1.        , 0.79166667],\n",
              "       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n",
              "       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n",
              "       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n",
              "       [0.20588235, 0.        , 0.42857143, 0.375     ],\n",
              "       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n",
              "       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n",
              "       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n",
              "       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n",
              "       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n",
              "       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n",
              "       [1.        , 0.81818182, 1.        , 0.875     ],\n",
              "       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n",
              "       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n",
              "       [0.35294118, 1.        , 0.05357143, 0.04166667],\n",
              "       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n",
              "       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n",
              "       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n",
              "       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n",
              "       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n",
              "       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n",
              "       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n",
              "       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n",
              "       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n",
              "       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n",
              "       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n",
              "       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n",
              "       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n",
              "       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n",
              "       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n",
              "       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n",
              "       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n",
              "       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n",
              "       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n",
              "       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n",
              "       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n",
              "       [1.        , 0.45454545, 0.89285714, 0.91666667],\n",
              "       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n",
              "       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n",
              "       [0.        , 0.45454545, 0.        , 0.        ],\n",
              "       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n",
              "       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n",
              "       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n",
              "       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n",
              "       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n",
              "       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n",
              "       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n",
              "       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n",
              "       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n",
              "       [0.58823529, 0.59090909, 0.875     , 1.        ],\n",
              "       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n",
              "       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n",
              "       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n",
              "       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n",
              "       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n",
              "       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n",
              "       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n",
              "       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n",
              "       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n",
              "       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n",
              "       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n",
              "       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n",
              "       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n",
              "       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n",
              "       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n",
              "       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n",
              "       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n",
              "       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n",
              "       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n",
              "       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n",
              "       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n",
              "       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n",
              "       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n",
              "       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n",
              "       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n",
              "       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n",
              "       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n",
              "       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n",
              "       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n",
              "       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n",
              "       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n",
              "       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n",
              "       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n",
              "       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n",
              "       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n",
              "       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n",
              "       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n",
              "       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n",
              "       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n",
              "       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR9zcSl0wRut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnEbn-EpyGH7",
        "colab_type": "code",
        "outputId": "3de2c90b-20cc-43ab-a220-1377c9f1a063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8,input_dim=4,activation='relu'))\n",
        "model.add(Dense(8,input_dim=4,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0tS3Ymw1GZo",
        "colab_type": "code",
        "outputId": "380f9499-0cd1-4c7f-a6d9-b8e025d31a80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTwt8gb91Ouk",
        "colab_type": "code",
        "outputId": "20aac589-ca07-4156-f952-1f0a11768647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_scaled,y_train,epochs=150,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 1s - loss: 1.0901 - acc: 0.3100\n",
            "Epoch 2/150\n",
            " - 0s - loss: 1.0858 - acc: 0.3100\n",
            "Epoch 3/150\n",
            " - 0s - loss: 1.0820 - acc: 0.3100\n",
            "Epoch 4/150\n",
            " - 0s - loss: 1.0780 - acc: 0.3100\n",
            "Epoch 5/150\n",
            " - 0s - loss: 1.0740 - acc: 0.3200\n",
            "Epoch 6/150\n",
            " - 0s - loss: 1.0702 - acc: 0.3200\n",
            "Epoch 7/150\n",
            " - 0s - loss: 1.0662 - acc: 0.3200\n",
            "Epoch 8/150\n",
            " - 0s - loss: 1.0621 - acc: 0.3300\n",
            "Epoch 9/150\n",
            " - 0s - loss: 1.0576 - acc: 0.3500\n",
            "Epoch 10/150\n",
            " - 0s - loss: 1.0522 - acc: 0.3800\n",
            "Epoch 11/150\n",
            " - 0s - loss: 1.0468 - acc: 0.4100\n",
            "Epoch 12/150\n",
            " - 0s - loss: 1.0406 - acc: 0.4500\n",
            "Epoch 13/150\n",
            " - 0s - loss: 1.0344 - acc: 0.4900\n",
            "Epoch 14/150\n",
            " - 0s - loss: 1.0283 - acc: 0.5200\n",
            "Epoch 15/150\n",
            " - 0s - loss: 1.0217 - acc: 0.5600\n",
            "Epoch 16/150\n",
            " - 0s - loss: 1.0152 - acc: 0.5800\n",
            "Epoch 17/150\n",
            " - 0s - loss: 1.0089 - acc: 0.5800\n",
            "Epoch 18/150\n",
            " - 0s - loss: 1.0019 - acc: 0.5800\n",
            "Epoch 19/150\n",
            " - 0s - loss: 0.9948 - acc: 0.5800\n",
            "Epoch 20/150\n",
            " - 0s - loss: 0.9879 - acc: 0.5800\n",
            "Epoch 21/150\n",
            " - 0s - loss: 0.9817 - acc: 0.5800\n",
            "Epoch 22/150\n",
            " - 0s - loss: 0.9749 - acc: 0.5700\n",
            "Epoch 23/150\n",
            " - 0s - loss: 0.9681 - acc: 0.5700\n",
            "Epoch 24/150\n",
            " - 0s - loss: 0.9618 - acc: 0.5700\n",
            "Epoch 25/150\n",
            " - 0s - loss: 0.9556 - acc: 0.5700\n",
            "Epoch 26/150\n",
            " - 0s - loss: 0.9492 - acc: 0.6200\n",
            "Epoch 27/150\n",
            " - 0s - loss: 0.9430 - acc: 0.6500\n",
            "Epoch 28/150\n",
            " - 0s - loss: 0.9364 - acc: 0.6700\n",
            "Epoch 29/150\n",
            " - 0s - loss: 0.9303 - acc: 0.6900\n",
            "Epoch 30/150\n",
            " - 0s - loss: 0.9240 - acc: 0.7200\n",
            "Epoch 31/150\n",
            " - 0s - loss: 0.9175 - acc: 0.7500\n",
            "Epoch 32/150\n",
            " - 0s - loss: 0.9111 - acc: 0.7700\n",
            "Epoch 33/150\n",
            " - 0s - loss: 0.9046 - acc: 0.7700\n",
            "Epoch 34/150\n",
            " - 0s - loss: 0.8978 - acc: 0.7400\n",
            "Epoch 35/150\n",
            " - 0s - loss: 0.8911 - acc: 0.7200\n",
            "Epoch 36/150\n",
            " - 0s - loss: 0.8844 - acc: 0.7200\n",
            "Epoch 37/150\n",
            " - 0s - loss: 0.8773 - acc: 0.7600\n",
            "Epoch 38/150\n",
            " - 0s - loss: 0.8706 - acc: 0.7700\n",
            "Epoch 39/150\n",
            " - 0s - loss: 0.8635 - acc: 0.7700\n",
            "Epoch 40/150\n",
            " - 0s - loss: 0.8558 - acc: 0.7600\n",
            "Epoch 41/150\n",
            " - 0s - loss: 0.8490 - acc: 0.7600\n",
            "Epoch 42/150\n",
            " - 0s - loss: 0.8423 - acc: 0.7500\n",
            "Epoch 43/150\n",
            " - 0s - loss: 0.8357 - acc: 0.7600\n",
            "Epoch 44/150\n",
            " - 0s - loss: 0.8289 - acc: 0.7900\n",
            "Epoch 45/150\n",
            " - 0s - loss: 0.8225 - acc: 0.8100\n",
            "Epoch 46/150\n",
            " - 0s - loss: 0.8160 - acc: 0.7900\n",
            "Epoch 47/150\n",
            " - 0s - loss: 0.8096 - acc: 0.7800\n",
            "Epoch 48/150\n",
            " - 0s - loss: 0.8032 - acc: 0.8000\n",
            "Epoch 49/150\n",
            " - 0s - loss: 0.7970 - acc: 0.8000\n",
            "Epoch 50/150\n",
            " - 0s - loss: 0.7907 - acc: 0.7900\n",
            "Epoch 51/150\n",
            " - 0s - loss: 0.7848 - acc: 0.8000\n",
            "Epoch 52/150\n",
            " - 0s - loss: 0.7789 - acc: 0.7900\n",
            "Epoch 53/150\n",
            " - 0s - loss: 0.7730 - acc: 0.8000\n",
            "Epoch 54/150\n",
            " - 0s - loss: 0.7670 - acc: 0.8000\n",
            "Epoch 55/150\n",
            " - 0s - loss: 0.7615 - acc: 0.8000\n",
            "Epoch 56/150\n",
            " - 0s - loss: 0.7560 - acc: 0.7900\n",
            "Epoch 57/150\n",
            " - 0s - loss: 0.7501 - acc: 0.8000\n",
            "Epoch 58/150\n",
            " - 0s - loss: 0.7447 - acc: 0.7800\n",
            "Epoch 59/150\n",
            " - 0s - loss: 0.7393 - acc: 0.7900\n",
            "Epoch 60/150\n",
            " - 0s - loss: 0.7340 - acc: 0.7900\n",
            "Epoch 61/150\n",
            " - 0s - loss: 0.7288 - acc: 0.8000\n",
            "Epoch 62/150\n",
            " - 0s - loss: 0.7235 - acc: 0.8100\n",
            "Epoch 63/150\n",
            " - 0s - loss: 0.7184 - acc: 0.8200\n",
            "Epoch 64/150\n",
            " - 0s - loss: 0.7135 - acc: 0.8200\n",
            "Epoch 65/150\n",
            " - 0s - loss: 0.7087 - acc: 0.8200\n",
            "Epoch 66/150\n",
            " - 0s - loss: 0.7040 - acc: 0.8100\n",
            "Epoch 67/150\n",
            " - 0s - loss: 0.6993 - acc: 0.8200\n",
            "Epoch 68/150\n",
            " - 0s - loss: 0.6947 - acc: 0.8200\n",
            "Epoch 69/150\n",
            " - 0s - loss: 0.6904 - acc: 0.8100\n",
            "Epoch 70/150\n",
            " - 0s - loss: 0.6857 - acc: 0.8200\n",
            "Epoch 71/150\n",
            " - 0s - loss: 0.6813 - acc: 0.8300\n",
            "Epoch 72/150\n",
            " - 0s - loss: 0.6769 - acc: 0.8300\n",
            "Epoch 73/150\n",
            " - 0s - loss: 0.6726 - acc: 0.8400\n",
            "Epoch 74/150\n",
            " - 0s - loss: 0.6684 - acc: 0.8400\n",
            "Epoch 75/150\n",
            " - 0s - loss: 0.6640 - acc: 0.8400\n",
            "Epoch 76/150\n",
            " - 0s - loss: 0.6598 - acc: 0.8400\n",
            "Epoch 77/150\n",
            " - 0s - loss: 0.6555 - acc: 0.8300\n",
            "Epoch 78/150\n",
            " - 0s - loss: 0.6514 - acc: 0.8300\n",
            "Epoch 79/150\n",
            " - 0s - loss: 0.6474 - acc: 0.8100\n",
            "Epoch 80/150\n",
            " - 0s - loss: 0.6433 - acc: 0.8100\n",
            "Epoch 81/150\n",
            " - 0s - loss: 0.6392 - acc: 0.8100\n",
            "Epoch 82/150\n",
            " - 0s - loss: 0.6352 - acc: 0.8000\n",
            "Epoch 83/150\n",
            " - 0s - loss: 0.6312 - acc: 0.8200\n",
            "Epoch 84/150\n",
            " - 0s - loss: 0.6272 - acc: 0.8200\n",
            "Epoch 85/150\n",
            " - 0s - loss: 0.6235 - acc: 0.8300\n",
            "Epoch 86/150\n",
            " - 0s - loss: 0.6198 - acc: 0.8400\n",
            "Epoch 87/150\n",
            " - 0s - loss: 0.6161 - acc: 0.8600\n",
            "Epoch 88/150\n",
            " - 0s - loss: 0.6122 - acc: 0.8500\n",
            "Epoch 89/150\n",
            " - 0s - loss: 0.6083 - acc: 0.8500\n",
            "Epoch 90/150\n",
            " - 0s - loss: 0.6046 - acc: 0.8400\n",
            "Epoch 91/150\n",
            " - 0s - loss: 0.6008 - acc: 0.8400\n",
            "Epoch 92/150\n",
            " - 0s - loss: 0.5971 - acc: 0.8400\n",
            "Epoch 93/150\n",
            " - 0s - loss: 0.5935 - acc: 0.8400\n",
            "Epoch 94/150\n",
            " - 0s - loss: 0.5898 - acc: 0.8300\n",
            "Epoch 95/150\n",
            " - 0s - loss: 0.5859 - acc: 0.8100\n",
            "Epoch 96/150\n",
            " - 0s - loss: 0.5827 - acc: 0.8100\n",
            "Epoch 97/150\n",
            " - 0s - loss: 0.5786 - acc: 0.8100\n",
            "Epoch 98/150\n",
            " - 0s - loss: 0.5752 - acc: 0.8000\n",
            "Epoch 99/150\n",
            " - 0s - loss: 0.5712 - acc: 0.8000\n",
            "Epoch 100/150\n",
            " - 0s - loss: 0.5674 - acc: 0.8000\n",
            "Epoch 101/150\n",
            " - 0s - loss: 0.5638 - acc: 0.8100\n",
            "Epoch 102/150\n",
            " - 0s - loss: 0.5601 - acc: 0.8100\n",
            "Epoch 103/150\n",
            " - 0s - loss: 0.5562 - acc: 0.8300\n",
            "Epoch 104/150\n",
            " - 0s - loss: 0.5524 - acc: 0.8600\n",
            "Epoch 105/150\n",
            " - 0s - loss: 0.5486 - acc: 0.8800\n",
            "Epoch 106/150\n",
            " - 0s - loss: 0.5448 - acc: 0.8800\n",
            "Epoch 107/150\n",
            " - 0s - loss: 0.5411 - acc: 0.8900\n",
            "Epoch 108/150\n",
            " - 0s - loss: 0.5374 - acc: 0.8900\n",
            "Epoch 109/150\n",
            " - 0s - loss: 0.5338 - acc: 0.8800\n",
            "Epoch 110/150\n",
            " - 0s - loss: 0.5303 - acc: 0.8800\n",
            "Epoch 111/150\n",
            " - 0s - loss: 0.5265 - acc: 0.9000\n",
            "Epoch 112/150\n",
            " - 0s - loss: 0.5227 - acc: 0.8900\n",
            "Epoch 113/150\n",
            " - 0s - loss: 0.5190 - acc: 0.8800\n",
            "Epoch 114/150\n",
            " - 0s - loss: 0.5152 - acc: 0.8900\n",
            "Epoch 115/150\n",
            " - 0s - loss: 0.5114 - acc: 0.8900\n",
            "Epoch 116/150\n",
            " - 0s - loss: 0.5074 - acc: 0.9000\n",
            "Epoch 117/150\n",
            " - 0s - loss: 0.5038 - acc: 0.9100\n",
            "Epoch 118/150\n",
            " - 0s - loss: 0.5005 - acc: 0.9200\n",
            "Epoch 119/150\n",
            " - 0s - loss: 0.4969 - acc: 0.9200\n",
            "Epoch 120/150\n",
            " - 0s - loss: 0.4936 - acc: 0.9300\n",
            "Epoch 121/150\n",
            " - 0s - loss: 0.4902 - acc: 0.9300\n",
            "Epoch 122/150\n",
            " - 0s - loss: 0.4864 - acc: 0.9200\n",
            "Epoch 123/150\n",
            " - 0s - loss: 0.4832 - acc: 0.9200\n",
            "Epoch 124/150\n",
            " - 0s - loss: 0.4799 - acc: 0.9200\n",
            "Epoch 125/150\n",
            " - 0s - loss: 0.4763 - acc: 0.9300\n",
            "Epoch 126/150\n",
            " - 0s - loss: 0.4729 - acc: 0.9300\n",
            "Epoch 127/150\n",
            " - 0s - loss: 0.4696 - acc: 0.9300\n",
            "Epoch 128/150\n",
            " - 0s - loss: 0.4665 - acc: 0.9200\n",
            "Epoch 129/150\n",
            " - 0s - loss: 0.4626 - acc: 0.9300\n",
            "Epoch 130/150\n",
            " - 0s - loss: 0.4592 - acc: 0.9300\n",
            "Epoch 131/150\n",
            " - 0s - loss: 0.4556 - acc: 0.9300\n",
            "Epoch 132/150\n",
            " - 0s - loss: 0.4522 - acc: 0.9400\n",
            "Epoch 133/150\n",
            " - 0s - loss: 0.4489 - acc: 0.9700\n",
            "Epoch 134/150\n",
            " - 0s - loss: 0.4465 - acc: 0.9600\n",
            "Epoch 135/150\n",
            " - 0s - loss: 0.4438 - acc: 0.9800\n",
            "Epoch 136/150\n",
            " - 0s - loss: 0.4409 - acc: 0.9800\n",
            "Epoch 137/150\n",
            " - 0s - loss: 0.4370 - acc: 0.9700\n",
            "Epoch 138/150\n",
            " - 0s - loss: 0.4325 - acc: 0.9600\n",
            "Epoch 139/150\n",
            " - 0s - loss: 0.4284 - acc: 0.9700\n",
            "Epoch 140/150\n",
            " - 0s - loss: 0.4248 - acc: 0.9700\n",
            "Epoch 141/150\n",
            " - 0s - loss: 0.4212 - acc: 0.9700\n",
            "Epoch 142/150\n",
            " - 0s - loss: 0.4180 - acc: 0.9700\n",
            "Epoch 143/150\n",
            " - 0s - loss: 0.4143 - acc: 0.9700\n",
            "Epoch 144/150\n",
            " - 0s - loss: 0.4111 - acc: 0.9700\n",
            "Epoch 145/150\n",
            " - 0s - loss: 0.4074 - acc: 0.9700\n",
            "Epoch 146/150\n",
            " - 0s - loss: 0.4042 - acc: 0.9700\n",
            "Epoch 147/150\n",
            " - 0s - loss: 0.4017 - acc: 0.9700\n",
            "Epoch 148/150\n",
            " - 0s - loss: 0.3982 - acc: 0.9600\n",
            "Epoch 149/150\n",
            " - 0s - loss: 0.3953 - acc: 0.9700\n",
            "Epoch 150/150\n",
            " - 0s - loss: 0.3926 - acc: 0.9700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88cadc00b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmKyilQ51fzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X_test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq-NX_Yv1-S-",
        "colab_type": "code",
        "outputId": "d42a5ff2-35ea-426f-8ed8-b857c3a9dacc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 1, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SErErxe2BKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = y_test.argmax(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZXnckF62JCL",
        "colab_type": "code",
        "outputId": "2a09b33e-a3e2-4447-f343-a173cb47ee3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       0.94      1.00      0.97        15\n",
            "           2       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.98      0.98      0.98        50\n",
            "weighted avg       0.98      0.98      0.98        50\n",
            "\n",
            "[[19  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 15]]\n",
            "0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOSjVfX02HhI",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4VMdu_b21Kc",
        "colab_type": "code",
        "outputId": "83a449e2-0990-4202-825e-5d736d9b1bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.distplot(y_test,hist=False,label='Actual Label',color='b')\n",
        "sns.distplot(y_pred,hist=False,label='Predicted Label',color='r')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f88701058d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3hU1dbH8e9Ko3eCSA0ivUNAkKYg\nEAiEJgICYgO9dr1XxetVFMuL5dquFUWx0RUBqVJEOgQp0ptUpUMgkEDKev84A4YYyKSeSbI+z5OH\nmVPm/GaANSf77LO3qCrGGGNyLz+3AxhjjMlaVuiNMSaXs0JvjDG5nBV6Y4zJ5azQG2NMLhfgdoDk\nSpcurSEhIW7HMMaYHGXNmjXHVDU4pXU+V+hDQkKIjIx0O4YxxuQoIrL3Suus6cYYY3I5rwq9iISJ\nyDYR2Skiw66yXW8RUREJTbLsGc9+20SkU2aENsYY471Um25ExB/4AOgAHABWi8g0Vd2cbLsiwKPA\nyiTLagP9gDpAOWCeiFRX1YTMewvGGGOuxps2+mbATlXdDSAi44HuwOZk270EvAY8mWRZd2C8qp4H\nfheRnZ7XW57R4MaY9ImLi+PAgQPExsa6HcWkQ/78+alQoQKBgYFe7+NNoS8P7E/y/ABwQ9INRKQx\nUFFVZ4jIk8n2XZFs3/LJDyAiQ4GhAJUqVfIuuTEmXQ4cOECRIkUICQlBRNyOY9JAVTl+/DgHDhyg\nSpUqXu+X4YuxIuIHvAX8M72voaqjVDVUVUODg1PsHWSMySSxsbGUKlXKinwOJCKUKlUqzb+NeXNG\nfxComOR5Bc+yi4oAdYGfPf9wygLTRCTCi32NMS6wIp9zpefvzpsz+tVANRGpIiJBOBdXp11cqapR\nqlpaVUNUNQSnqSZCVSM92/UTkXwiUgWoBqxKc0rjroQE2LQJDh8GG9bamBwn1UKvqvHAQ8AcYAsw\nUVU3icgIz1n71fbdBEzEuXA7G3jQetzkIJs2wdChUK4c1K0LZctC0aLQpw/s2OF2OpPD/fDDD4gI\nW7duTXXbMWPG8Mcff6T7WD///DNdu3b1evmV3HTTTWm6oTOtr59VvGqjV9WZqlpdVauq6iueZc+r\n6rQUtr3JczZ/8fkrnv1qqOqszItustSECdCsGYwbBzffDF98Ae+9B4MGwaxZULs2PP44XLjgdlKT\nQ40bN45WrVoxbty4VLfNaKHP6+zOWHM5VXj2WejXDxo1gh07ODt6PL+3vZO9EQ9z4uUPYedOuOsu\neOcdiIiAs2fdTm1ymOjoaJYsWcLo0aMZP378Zetee+016tWrR4MGDRg2bBiTJ08mMjKSAQMG0LBh\nQ2JiYggJCeHYsWMAREZGctNNNwGwatUqWrRoQaNGjbjxxhvZtm1buvKNGDGCpk2bUrduXYYOHUrS\nmfi+/vprGjZsSN26dVm1ymmJPnv2LHfffTfNmjWjUaNGTJ06NV3HzSo+N9aNcdno0fDqq3DPPez+\n14e8+39BfP45REc7q0Wga9eyPPTQKDo0uwG5byi0bw8zZ0LJku5mN2n22GOwbl3mvmbDhs45wNVM\nnTqVsLAwqlevTqlSpVizZg1NmjRh1qxZTJ06lZUrV1KwYEFOnDhByZIlef/993nzzTcJDQ296uvW\nrFmTxYsXExAQwLx58/j3v//Nd999l+b38NBDD/H8888DMGjQIH788Ue6desGwLlz51i3bh2//PIL\nd999Nxs3buSVV16hXbt2fP7555w6dYpmzZpxyy23pPm4WcUKvfnLr7/CQw9Bx46MbvYJ99X1R8Q5\nuW/Xztlk+3bnu2D6dOjS5R4mfFmKwvf0hd69Ye5cSMNNHCbvGjduHI8++igA/fr1Y9y4cTRp0oR5\n8+Zx1113UbBgQQBKpvHkISoqisGDB7Njxw5EhLi4uHTlW7hwIa+//jrnzp3jxIkT1KlT51Kh79+/\nPwBt2rTh9OnTnDp1irlz5zJt2jTefPNNwOnCum/fvnQdOytYoTeOkyehd2+0TBneCf2WJ+7zp1Mn\n+Pxz51psUi+8AB9/DE8+CQ229mDh8NFUenYQPPIIfPSRK/FN+qR25p0VTpw4wYIFC/jtt98QERIS\nEhAR3njjDa9fIyAggMTERIDL+pQ/99xz3HzzzUyZMoU9e/ZcatJJi9jYWB544AEiIyOpWLEiL7zw\nwmXHSN69UURQVb777jtq1Khx2brDhw+n+fhZwdrojeOFF2DfPr4Im8gTr5ZmwADnrD15kQfIlw8e\nfRQWLYLYWKj32kCO3PmUU/2t0JtUTJ48mUGDBrF371727NnD/v37qVKlCosXL6ZDhw588cUXnDt3\nDnC+FACKFCnCmTNnLr1GSEgIa9asAbisaSYqKory5Z2b78eMGZOufBeLeunSpYmOjmby5MmXrZ8w\nYQIAS5YsoVixYhQrVoxOnTrxv//971Jb/tq1a9N17Kxihd447TEffsgf4UO497PmDBwIX32VeitM\nixawfLnT47LRrFc5d1MXp9F348bsyW1ypHHjxtGzZ8/LlvXu3Ztx48YRFhZGREQEoaGhNGzY8FJT\nyJ133sn9999/6WLs8OHDefTRRwkNDcXf3//S6zz11FM888wzNGrUiPj4eK/yzJ8/nwoVKlz62bJl\nC0OGDKFu3bp06tSJpk2bXrZ9/vz5adSoEffffz+jR48GnN8k4uLiqF+/PnXq1OG5557LyEeU6UR9\n7AaY0NBQtYlHslnPnuhP82hcdCdnC1/Dr79C4cLe7755M7RqBdWKH2V5dF38yl0Lq1ZBUFDWZTbp\ntmXLFmrVquV2DJMBKf0disgaVU3xarWd0ed1ixbBDz8wLuQZNh27hnHj0lbkwelSP2MGrP8jmJcq\nfQbr1ztNQcYYn2CFPq/7z3+IDa7APZse58UXoUmT9L1Mixbw1lvwwppu/NbsHnjtNVi9OnOzGmPS\nxQp9XrZ6NSxZwvv5/sU1lQvwxBMZe7l//MPpZdl2zVtcKHmNsyDBRrwwxm1W6POyd94hrkARRhy4\nixEjnN40GSECn30GxSoW5amAt2HNGvjkk8zJaoxJNyv0edXBg+jEiXwddC+V6xZlwIDMednixZ0b\nqt49dBvbK98C//63M+qlMcY1VujzqvffRxMSeSnqYf7v/yBJD7UMa9cOhg4VIvZ9QOK5GOfOKmOM\na6zQ50UxMegnnzC/SA+KNahCeHjmH+L11yG6XHU+Lf4UfP01/Pxz5h/E5Fj+/v6XBgbr06fPpRuk\n0iPpUMDTpk1j5MiRV9z21KlTfPjhh2k+xgsvvHCpT783y6+kcBq7tKX19a/ECn1eNHUqcvIkI08/\nwKOPOm3rma1YMedG2ceO/ptTJavAAw/YkMbmkgIFCrBu3To2btxIUFAQH3/88WXrVfXSEAdpERER\nwbBhw664Pr2FPqezQp8XffUVRwtU5LdSN+MZnylLdO0KnXsW4J6z78GWLfD221l3MJNjtW7dmp07\nd7Jnzx5q1KjBHXfcQd26ddm/fz9z586lRYsWNG7cmD59+hDtGUZ19uzZ1KxZk8aNG/P9999feq0x\nY8bw0EMPAc44Mz179qRBgwY0aNCAZcuWMWzYMHbt2kXDhg150tOk+MYbb9C0aVPq16/P8OHDL73W\nK6+8QvXq1WnVqlWahzvu0aMHTZo0oU6dOowaNeqydY8//jh16tShffv2HD16FIBdu3YRFhZGkyZN\naN26tVeTsaSFDWqW1xw6hM6Zw6eJwxj6hB/582ft4d59F2rN7cqKEj1oPmIE9O8PlSpl7UGN99wa\np9gjPj6eWbNmERYWBsCOHTv48ssvad68OceOHePll19m3rx5FCpUiNdee4233nqLp556iiFDhrBg\nwQKuv/56+vbtm+JrP/LII7Rt25YpU6aQkJBAdHQ0I0eOZOPGjazzvOe5c+eyY8cOVq1ahaoSERHB\nL7/8QqFChRg/fjzr1q0jPj6exo0b0yQNN5l8/vnnlCxZkpiYGJo2bUrv3r0pVaoUZ8+eJTQ0lLff\nfpsRI0bw4osv8v777zN06FA+/vhjqlWrxsqVK3nggQdYsGCB18dLjVeFXkTCgHcBf+AzVR2ZbP39\nwINAAhANDFXVzSISgjP94MWvwxWqen/mRDfpMnYskpjIWP9BzPlH1h+uYkUYPhz6PvUOu4JqEfDY\nY5DkDMzkTTExMTRs2BBwzujvuece/vjjDypXrkzz5s0BWLFiBZs3b6Zly5YAXLhwgRYtWrB161aq\nVKlCtWrVABg4cODfzpoBFixYwFdffQU41wSKFSvGyZMnL9tm7ty5zJ07l0aNGgHOhCg7duzgzJkz\n9OzZ89JwyRERV5019W/ee+89pkyZAsD+/fvZsWMHpUqVws/P79IX08CBA+nVqxfR0dEsW7aMPn36\nXNr//PnzaTpealIt9CLiD3wAdAAOAKtFZJqqbk6y2VhV/dizfQTwFhDmWbdLVRtmamqTbolffsVa\n/2bU7lUTzyB/We6xx+Crryrz3/3P8fSUfztTEXbunD0HN1fnxjjF/NVGn1yhQoUuPVZVOnTo8Lep\nBlPaL71UlWeeeYb77rvvsuXvZOBz+fnnn5k3bx7Lly+nYMGC3HTTTZcNc5yUiJCYmEjx4sUz9X0l\n500bfTNgp6ruVtULwHige9INVPV0kqeFAN8aKc041q/Hb8N6Pk+4gzvvzL7DBgY6oxc/F/VPjpSs\nAQ8/7IxvbMxVNG/enKVLl7Jz507Ama5v+/bt1KxZkz179rBr1y6AK8452759ez7yDJudkJBAVFTU\n34Y77tSpE59//vmltv+DBw9y5MgR2rRpww8//EBMTAxnzpxh+vTpXueOioqiRIkSFCxYkK1bt7Ji\nxYpL6xITEy8Nezx27FhatWpF0aJFqVKlCpMmTQKcL5/169d7fTxveFPoywP7kzw/4Fl2GRF5UER2\nAa8DjyRZVUVE1orIIhFpnaG0JmPGjydeAlhQui8dO2bvoVu1goF3BTHw1Aewa5czFo4xVxEcHMyY\nMWPo378/9evXv9Rskz9/fkaNGkV4eDiNGzemTJkyKe7/7rvvsnDhQurVq0eTJk3YvHkzpUqVomXL\nltStW5cnn3ySjh07cvvtt9OiRQvq1avHrbfeypkzZ2jcuDF9+/alQYMGdO7c+W9DFSf18ssvXzbM\ncVhYGPHx8dSqVYthw4ZdaooC5zeWVatWUbduXRYsWHBpusJvv/2W0aNH06BBA+rUqZPpc86mOkyx\niNwKhKnqvZ7ng4AbVPWhK2x/O9BJVQeLSD6gsKoeF5EmwA9AnWS/ASAiQ4GhAJUqVWqyd+/ejL4v\nk5wqCdVqsHB3CD8+MteV39iPHYMaNWCif3/anZ6CbNoEVatmfxBvREfDTz/BypVw/DhERTkXHOrV\ng9atfTe3F2yY4pwvK4YpPghUTPK8gmfZlYwHegCo6nlVPe55vAbYBVRPvoOqjlLVUFUNDQ4O9iKS\nSbPNm/HftYPJ2os77nAnQunSMHIkDDr6X+IkyJl60MfmQ2DdOrj1Vidsr17OkJwzZjhDL3/4Idx1\nF1x/PXTpAnPm+F5+Y1LgTaFfDVQTkSoiEgT0A6Yl3UBEqiV5Gg7s8CwP9lzMRUSuA6oBuzMjuEmj\nKVNIRNhSrTueDgauuOceCGlRjpf8X4SZM+GHH9wLk9Tevc7Qm40awbx5zsibCxbA2bPwxx+wbZtz\nlr9lizPW/tq1EBbmfCnYWD7G16lqqj9AF2A7zhn5s55lI4AIz+N3gU3AOmAhTvMMQO8ky38FuqV2\nrCZNmqjJfLF1GukSbtSRI91OorpunWqQX5zuL1Vf9dprVU+ccC9MYqLqxx+rFi6sWqiQ6vDhqidP\npr7f+fOqr72mmi+faqlSqjNmZHnUzLJ582ZNTEx0O4ZJp8TERN28efPflgOReqUafqUVbv1Yoc8C\nu3ergj7Bm/r7726HcTz+uGpj1miCf4DqwIHuhIiKUo2IcP4btGun6fpwNm1SbdRI1c9P9dNPMz1i\nVti9e7cePXrUin0OlJiYqEePHtXdu3f/bd3VCr3dGZsXeJpHttfuSUiIu1EuevFFqDmhMZ8mPst9\n37zoNJv06JF9AXbsgO7dnYnR337buV7gl44RQWrXhl9+gT59YMgQ+PNP8LGJoZOrUKECBw4cuHT7\nvclZ8ufPT4UKFdK0jxX6POD8hClsoQE39L/O7SiXFCni3Ktz+23P0qv8VILvuw9uuAGuvTbrDz5n\nDvTr54zN/NNPcPPNGXu9woVh2jS49154/nnIn9+nh2YODAykSpUqbscw2cgGNcvtTp4kcNVSptON\nXr3cDnO5W2+F9p0CCT/5DYlnoqFvX4iLy7oDqsJ//+v0mKlUCSIjM17kLwoMhM8/d97DU085j43x\nEVboc7uffsJPE9lUqQu+1nVaBN5/HzYk1OG9OqNg8WJnRqqsEBMDgwfDv/7lNBMtW0amt2P5+8NX\nX0GnTk4zzsyZmfv6xqSTFfpc7vyUmRynJNf1a5Yl485n1PXXw0svweORA9jS7kF480349tvMPcjB\ng9C2rTMByksvwYQJkGRMlUwVFATffQcNGjgjdaZxeFtjskKqd8Zmt9DQUI2MjHQ7Ru6QmEhMiXL8\ncPpmrl81jqvcxe2qxES45RZYt+oCB+t0pMCaJTBlCnTrlvEXX7ECevZ0+sB/841zATY77NsHoaFQ\nooRzd23x4tlz3Ey2bh3Mn+/cNrB/v3NzcNWqzr1kDRq4nc4kdbU7Y63Q52a//gpNmvBoiS955/gd\nPnlGf9H+/VC/PjSqepp5cgt+v21w7kht3z79LzpmDNx3H1SoAFOnQt26Xu2m6tw/tWoVbN3qfEfE\nxDjXiatWhcaNoVq11F+HxYud/GFhzvF9+S8gmYUL4dVXnXvHwPkIQ0Kcv6f9+50v5+7dnXvHGtrY\ntD7haoXe9X7zyX+sH33miXvxZVXQfw485HYUr0ya5HRpf/yOY5pYp45qYKDqJ5+k/YWOHlXt2/ev\n/vHHjnm128aNqsOGqVaq5Ox68SdfPtVixS5fVreu6osvqh45ksqLvvees8Pbb6f9fbggKkp18GAn\nctmyzj1hyd/jyZPOey9e3Pkr+vprV6KaZLAbpvKmU3Vu1NU00SlT3E7ivWHDnH+Vn71+XLVTJ+fJ\nvfd6d7dqXJzq55+rlinjVKCXX3aWpWLDBtVu3ZxD+furdu6s+sEHqpGRqrGxf20XHa26fr3qu++q\ntmmjKuLcTPv006rHj1/hxRMTVXv0cPKsXu3dh+CSVatUq1Rx7v36z39UY2Kuvv3x46o33eR8biNG\nOG/VuMcKfV504oQmiJ++4vcfPX3a7TDei49XDQ93Cu6cmfGqzzzj/DMtXlz1lVdUD6Xw28mBA6of\nfqh6/fXOtk2bOhU5Fbt3qw4a5BTsokVVX3op5Ze/ki1bVG+/3dm/TBnV7767wobHjzu/Jlx3neqp\nU94fIBtNm6ZaoIBq5cqqS5Z4v19srHNjM6j+3/9lWTzjBSv0eZGnHeSRJmn4X+sjoqJU69dXzZ9f\n9aefVHXt2r9OuUG1alXntPumm1Tr1PlrecOGqj/8kOqp5aFDqg8/7Jxk58+v+uSTXrfupGj9etXG\njZ0I/fppyl+sS5c63159+/rcqe8nnzhn8aGhafuiuygx0XlbIqqzZ2d+PuMdK/R50OmB9+tpCuvb\nr19wO0q6HDmiWq+eU4jnzvUsXLdO9Y03nKaQJk1UW7dW7dpVdeRI1d9+S7WARkWpPvec09zi7686\nZIjq/v2Zk/fCBaelyN9ftVYt1a1bU9jo1Ved/3KjRmXOQTPBRx85kTp3Vj1zJv2vEx3t/H2VKKG6\na1fm5TPes0KfB50sU02nE65btridJP0uFvuAANU330z/iXBMjOp//+sMMgmqffpcoRBnggULVEuX\ndpqC5sxJtjIhQbVDB+fb67ffsiZAGowZ43we4eHOYJwZtWuXU+hvuMF5qyZ7WaHPa/buVQUdUeIt\nX2slSLOTJ1V79XL+pUZEOG/NW6dPOwW+fHln/w4dsud66N69qg0aOE1D48YlW3nokOo11zin/dHR\nWR/mCsaPd5prbrnlKhddN2xQfeopp+dSyZKqwcHON2/fvs43Wgr/uL76yvms09NZymSMFfo8Jm7U\n56qgL9+W+gXJnCAxUfWdd1SDgpzief/9Tg1K6UssPl514ULV++5zrt+C05Q/b172Zj516q+eOf/7\nX7KV8+c7KwYPzt5QHlOmOE1MrVtf4btm8WLVjh2dDy8w0GkmGzLE+VC7d//rV6M6dZxrD0kkJqq2\nbeuc2afa9dRkKiv0ecyhWwboIcroD9/nrt+f9+1zinxgoPMvt0wZp9nhttuci6BNmzo9R0C1YEHV\n/v1VV6xwL29MjFMXQfX555N9MQ0f7qz44otszTRrlvOFecMNKVw0PnVKdehQvdSJ/pVXUr5Kfe6c\nk7tKFadd7b33LntzmzY5i++8M0vfiknGCn1ekpiopwuX1XHSz1d78mXYwYNOd/lBg5wmkpo1nY44\n7ds7E5pMmOBqq8hl4uJU777b+Z/2j384v3GoqvPg5pudb6aNG7Mly4IFzuWBRo1SuC1hyRKnjcvP\nT/Vf/1I9ezb1Fzx58q/eUPfff1mxf/ppZ/Gvv2buezBXZoU+L9m0SRX01etyxmxHeUFiotPUDU7z\n9qULn3/+6bTX166d5d9MS5c6vY3q1HFuHL4s3HvvOafgVas6d02lRUKC0z8VnN8APE6edO4m7tEj\nc/Kb1GW40ANhwDZgJzAshfX3A7/hzA27BKidZN0znv22AZ1SO5YV+ow5+5pzy/1/H/7d7Sgmmdde\nc/7HhYUlOWGeN89pr7/rriw77urVTi+gatWc75ZLzp93jgvOmbk3dx+nJDHR+fUKLhsP4YUXnEVr\n12Ysv/FOhgo94I8zKfh1QBCwPmkh92xTNMnjCGC253Ftz/b5gCqe1/G/2vGs0GfMwea9dDchumiR\n20lMSj791GkdadkySV19/nnnv+IHH2T68davdy6MhoQ41zguOXnS6U1z8QJCRvtDnj/vNEUFBV3q\nOnrxrL5nz4y9tPFORgt9C2BOkufPAM9cZfv+wKyUtgXmAC2udjwr9BmQmKhRBcrotwGDMqVftMka\nkyY5F5QbNPCcYcfHO31H/f1T6Hyffps3Oxesy5d3hnu4ZNcup3tnYKDTHzKzHDnidMEMDb00xtDF\na852Vp/1rlbovZl4pDywP8nzA55llxGRB0VkF/A68Ega9x0qIpEiEmkTFmfArl0UjTnC8ZqtCApy\nO4y5kltvhR9/dOYnb9kStmz3dyZbqVvXmWR88+YMH2PlSmjd2hkZecECuDRF7LJlzty8hw458+UO\nGpThY10SHOxMGRYZ6UzZCDz2mDM/sOepcUmmzTClqh+oalXgaeA/adx3lKqGqmpocHBwZkXKc45P\nXQJAsS4tXU5iUtOxozOhR3S0U3dn/lIYpk+HggWdWVh27Ej3a8+aBe3aQbFisGQJVK/uWTFunLOi\nRAlnQpa2bTPnzSTVp48zVePzz8PWrRQvDnfe6Uzqdfhw5h/OeMebQn8QqJjkeQXPsisZD/RI574m\nA45PXcIJStDodh+bHNakqHlzWL3amcyka1f4zycViZs1z5kgvV07+P33NL1eQgKMGOG8Vo0azsn7\n9dfjDPn24otw++3Ot8ry5UmqfyYTgQ8+gAIF4OmnAXjwQectffpp1hzSeOFKbTr6V7t6ALAb52Lq\nxYuxdZJtUy3J42542oqAOlx+MXY3djE2yxwsWkNnB3XN8cMe5DXR0c7NReCMgrlj8jpnyIEKFbzu\niL53r3MfATjDBl8aoOzECdXevZ0VgwdnzqA23rg4gJtnzOOOHVXLlXMGfzNZg0zoXtkF2I7Ta+ZZ\nz7IRQITn8bvAJpzulQuTfhEAz3r22wZ0Tu1YVujTJ/HwEVXQb+qNdDuKSafvv3cGRPPzU30uYp3G\nlavo3FA1ceIV94mKcobsz5fP2fSzz5Lct7R4sTMOfkCAM+pndp4BREc7d9e2aqWamKjTpzvV5ipv\nxWRQhgt9dv5YoU+fPz76QRX0uydy3vjz5i9Hj6r+859O4b7W75BuLNZCFfRY+B16ZMOfGhXl9F6c\nNMm5+erikA8DBybpPnnwoOodd+ilsftXrnTnzVwcA/nHHzU+3hkxoXVrd6LkBVbo84D1nf6lsQTp\nlrWpzP9mcoT9+50z9TrXx+qrDNPzBGoURfQlntVabFJwzv7/8Q/VNWvUOVtfvtwZq6ZQIac/+9NP\nX2EWlGxy4YIz61ejRqqJiTpypFNxtm93L1JudrVCL8563xEaGqqRkZFux8hxdgS34ESUP83OL0HE\n7TQms6jC1q1wYMF2qn7yJCEbf8RPE4mtUJWgapXxCy4NBw/Ctm1w7JhzEfS225xeL9dd53Z8GD0a\n7r0X5s/nYI12VKoE//43vPSS28FyHxFZo6qhKa6zQp/z6dlzxBUuzsyaT9Bjy0i345isdOgQTJoE\nP//sPD56FK691ulm07y500m/aFG3U/4lNhYqV4YmTWDmTDp3hk2bYM8e8Mu0zt0Grl7oA7I7jMl8\nB39YTQXiCGrXyu0oJquVLQsPP+z85AT58ztZn3sONm1i8OA69O8PCxdC+/Zuh8s77Ds1F/hz8lIA\nrh90o8tJjEnBP/7hNCm99Rbduzs3co0Z43aovMUKfS4QuHIJ2wJqU+2Gkm5HMebvSpWCu+6Cb76h\nwOnD9OsH330Hp0+7HSzvsEKfw2l8AlUOLWN/pVZ2Edb4rkcegQsXYMwYBg+GmBiYMsXtUHmHFfoc\n7uDcTRTTKGhl7fPGh9WoAW3awGef0bxZIpUrO+PfmOxhhT6HOzDeGcisQj8r9MbHDRkCO3cii37m\nttucwTNPnHA7VN5ghT6nW7aUP6Qc1TuGuJ3EmKvr3RuKF4dPP6VvX4iPt+ab7GKFPoeruHcJu8u2\nxM/fGuiNjytQAO64A77/nsaVjnHdddZ8k12s0OdgRyL3UT5+H+ebWrONySGGDIELF5BvvqZvX2dS\nFJtrKOtZoc/Bfv/G6T8f3MsKvckh6taF0FD45hv69nXG0P/+e7dD5X5W6HOwCwuWcIbC1OxT3+0o\nxnhv4ED49VfqB26hRg1nRIbBKrkAAB4cSURBVAeTtazQ52Bldixle4nmBBW0kSxMDtK3L/j5IWO/\npVcvZ9iekyfdDpW7WaHPoaL2RVEtdgOn61uzjclhypZ15sUdO5Ye3ZWEBGeydJN1rNDnUNu/XI4f\nSvGuVuhNDjRgAPz+O6FxyylXDn74we1AuZtXhV5EwkRkm4jsFJFhKax/QkQ2i8gGEZkvIpWTrEsQ\nkXWen2mZGT4vi569hHj8qXHHDW5HMSbtevaEAgXwG/sNPXrA7NnOsAgma6Ra6EXEH/gA6AzUBvqL\nSO1km60FQlW1PjAZeD3JuhhVbej5icik3HlesY1L2V6oEQXLFHY7ijFpV6QIRETAxIn07BbPuXPO\nnbIma3hzRt8M2Kmqu1X1AjAe6J50A1VdqKrnPE9XABUyN6ZJKvb0BWqeXsnxmi3djmJM+vXtC8eP\nc5Msolgxu0s2K3lT6MsD+5M8P+BZdiX3ALOSPM8vIpEiskJEeqQjo0lmy9i1FCSGArdY+7zJwcLC\noFAhAqZMomtXmD7dGRbBZL5MvRgrIgOBUOCNJIsre6a3uh14R0SqprDfUM+XQeRRu00uVcenOgOZ\nVb3DzuhNDlagAHTtCt9/T/duCRw/DitWuB0qd/Km0B8EKiZ5XsGz7DIicgvwLBChqucvLlfVg54/\ndwM/A42S76uqo1Q1VFVDg4OD0/QG8qICvy5hX1BVStS+1u0oxmTMrbfC0aN0LrSYgACYMcPtQLmT\nN4V+NVBNRKqISBDQD7is94yINAI+wSnyR5IsLyEi+TyPSwMtgc2ZFT4vio9Tqh9dyh9VrNnG5AKd\nO0OBAhSeNYlWrazQZ5VUC72qxgMPAXOALcBEVd0kIiNE5GIvmjeAwsCkZN0oawGRIrIeWAiMVFUr\n9BmwdfoOgvUofq2t2cbkAoUKQXg4fP894WEJ/PYb7N+f+m4mbby6d15VZwIzky17PsnjW66w3zKg\nXkYCmsv9MXEJdYHKA+yM3uQSt94Kkydza7llPElrZs6E++5zO1TuYnfG5jD+y5dwwq8U17St6XYU\nYzJHly4QFETl9dMICbHmm6xghT4HUYWQg0vYU64lNhO4yTWKFIGbbkKmT6NLF5g/H2Jj3Q6Vu1ih\nz0F2LT9C1YQdxDW3ZhuTy0REwPbt3NZgG+fOwaJFbgfKXazQ5yAXJxop28suxJpcpls3AG48Pp0C\nBaz5JrNZoc9B4hctIZZ8VOrZxO0oxmSuSpWgYUMCZ02jXTun0Ku6HSr3sEKfg1y7awm7SzVD8udz\nO4oxma9bN1i6lJ5tjrN7N2zf7nag3MMKfQ7x565z1Dn/K9ENrX3e5FIREZCYSPdApye3Nd9kHiv0\nOcSWL1cRSDwlulmhN7lU48ZQrhyll02jTh0r9JnJCn0OcXauM5BZldtbuJzEmCzi5+c038yeTUSn\n8yxeDKdPux0qd7BCn0OU3LSE3wvXJSC4hNtRjMk6EREQHU2/axcRFwfz5rkdKHewQp8DnDqeQL3o\nZRyvZc02Jpdr1w4KFqTO7mkUK2bNN5nFCn0O8NvY3yjKGQp2sEJvcrn8+aFjR/x/nEanjsrMmdbN\nMjNYoc8BTkx3bpSqMtBulDJ5QEQE7N/P7XU3cOgQbNjgdqCczwp9DlBo7RKOBJWnQM3KbkcxJuuF\nh4MI7aKd0c7nzHE5Ty5ghd7HxcYoNY8t5o/rWtlAZiZvKFMGmjenyMJpNGgAs2e7HSjns0Lv4zb8\nuI8KHMS/jbXPmzwkIgIiI+nT8g+WLIEzZ9wOlLNZofdxf05y+s9X7G+F3uQh4eEA9C44i7g4WLjQ\n5Tw5nBV6H+e/YinRfkUo3tom6jJ5SN26ULEi1XfMoHBha77JKK8KvYiEicg2EdkpIsNSWP+EiGwW\nkQ0iMl9EKidZN1hEdnh+Bmdm+NwuIcGZaGRfuRbg7+92HGOyjwiEh+M3/yc6tj3PrFnWzTIjUi30\nIuIPfAB0BmoD/UWkdrLN1gKhqlofmAy87tm3JDAcuAFoBgwXEbu100ubl56kduJG4m2iEZMXhYdD\ndDSDqy5mzx7YscPtQDmXN2f0zYCdqrpbVS8A44HuSTdQ1YWqes7zdAVQwfO4E/CTqp5Q1ZPAT0BY\n5kTP/X4fuxw/lGt6W6E3eVC7dpAvH23POLfHWvNN+nlT6MsD+5M8P+BZdiX3ALPSsq+IDBWRSBGJ\nPHr0qBeR8oaERUuII4BrujVzO4ox2a9gQbj5ZootnUn16lboMyJTL8aKyEAgFHgjLfup6ihVDVXV\n0ODg4MyMlGOpQtldS9lXqhEUKuR2HGPcER4O27czsPlOfv4ZYmLcDpQzeVPoDwIVkzyv4Fl2GRG5\nBXgWiFDV82nZ1/zdrs3naRi3irM20YjJyy52s8w/g5gYWLzY5Tw5lDeFfjVQTUSqiEgQ0A+YlnQD\nEWkEfIJT5I8kWTUH6CgiJTwXYTt6lplUbBv3KwWItYlGTN5WpQrUqkWNnTPIl8+ab9Ir1UKvqvHA\nQzgFegswUVU3icgIEYnwbPYGUBiYJCLrRGSaZ98TwEs4XxargRGeZSYVFycaKX+bDWRm8rjwcPyX\nLKJTy2gr9Okk6mOdU0NDQzUyMtLtGK6bV7g7tdhC+WibIdnkcT//DDffzLS7ptD9ix7s2QOVbXy/\nvxGRNaoamtI6uzPWBx36I5FGZ5dwspadzRtDy5ZQrBitPd0sbTTLtLNC74N+m7CZUpygQFhbt6MY\n477AQOjYkeLLZlKpolrzTTpYofdBUdMWAVBpkBV6YwAID0f++IMhTdcxbx7ExbkdKGexQu+Diq5b\nxJF8FQisFuJ2FGN8Q+fOIEKvfDM4cwaWL3c7UM5ihd7HnDiu1D/1C4drtLWJRoy5qEwZaNqU6jtn\nEBBg3SzTygq9j/l1/HbKcpj8nazZxpjLdOlCQORKOocetUKfRlbofcyx738BoPKgNi4nMcbHhIeD\nKkMqzmbtWjh0yO1AOYcVeh9TeM0iTgRdQ1Dd6m5HMca3NG4M11xDqyinm+XcuS7nyUGs0PuQo0eU\nBlGLOFy9jbXPG5Ocnx906ULxVXMoVybemm/SwAq9D1k1aQ8VOWDt88ZcSXg4cuoUDzRazty5zixs\nJnVW6H3I8e+c/vMVBlihNyZFHTpAYCA9g2Zw/DisWeN2oJzBCr0PKfTrL5wOLElgg+QzNRpjACha\nFFq3pvrOGYhYN0tvWaH3EX/+CQ0vts/72V+LMVcUHk7Alo10rb/PCr2XrKL4iJXfHaAqu8nf0bpV\nGnNVnslIhpafwcqVcMIGPk+VFXofcbH/fLn+1j5vzFVVrw5Vq9Ly1AwSE2HePLcD+T4r9D6i0Jpf\nOBtQFP/GDdyOYoxvE4HwcIqvXcC1xWOs+cYLVuh9wIED0PD0Ig5XawX+/m7HMcb3hYcjMTE8XHch\ns2eDj82f5HO8KvQiEiYi20Rkp4gMS2F9GxH5VUTiReTWZOsSPNMLXppi0Fxu+Q+HqcVW8ne0Zhtj\nvNKmDRQsSI/AGfz5J/z2m9uBfFuqhV5E/IEPgM5AbaC/iCTv/7cPuBMYm8JLxKhqQ89PRArr87wj\n3ztT25fta4XeGK/kzw+33EK1HTMAZdYstwP5Nm/O6JsBO1V1t6peAMYD3ZNuoKp7VHUDkJgFGXO9\nwpGLiPUviF9oY7ejGJNzhIcTcGAvvWtuZvp0t8P4Nm8KfXlgf5LnBzzLvJVfRCJFZIWI9EhpAxEZ\n6tkm8ujRo2l46Zxvzx5oema+038+MNDtOMbkHF26AE43y+XL4dgxl/P4sOy4GFvZMzP57cA7IlI1\n+QaqOkpVQ1U1NDg4OBsi+Y6V3x+kNlsI6tLe7SjG5CwVKkCDBrQ44XSznDnT7UC+y5tCfxComOR5\nBc8yr6jqQc+fu4GfgUZpyJfrnZi8AICyA25xOYkxOVB4OIU3LKXmNSet+eYqvCn0q4FqIlJFRIKA\nfoBXvWdEpISI5PM8Lg20BDanN2xuk5gIJdbO53S+0kiD+m7HMSbnCQ9HEhJ4rM5PzJkDFy64Hcg3\npVroVTUeeAiYA2wBJqrqJhEZISIRACLSVEQOAH2AT0Rkk2f3WkCkiKwHFgIjVdUKvceG9Uqr2Hmc\naNDOxrcxJj1uuAFKlaKLOpOGL1rkdiDfFODNRqo6E5iZbNnzSR6vxmnSSb7fMqBeBjPmWpFjt3Mv\nBzl1q7XPG5Mu/v4QFkaFObMokC+R6dP96NDB7VC+x04jXXRumjNIR/FeVuiNSbfwcOTYUf4Ruprp\n0+0u2ZRYoXfJ2bNQacd8ThQNgeuuczuOMTlXp07g58eA4jPYswc2bUp1jzzHCr1LFi+Mp60u5NyN\n7W1+WGMyomRJaNGCent/BLDeNymwQu+SrV+vpgSnCB7Yye0oxuR83boRuHEt4fX2Mc1G1PobK/Qu\nCVowmwT8yNfF+s8bk2E9ewLwYIWprFwJR464nMfHWKF3wd690OTYbA5XvgFKlHA7jjE5X/XqULs2\nrY5OQRVmzHA7kG+xQu+CeROO05TVBEWEuR3FmNyjZ08Kr/2Futcet3b6ZKzQu+DYuJ/wQyk1wAq9\nMZmmZ08kIYF/1ZjO3LkQG+t2IN9hhT6bxcRAuQ2zic5fCglt4nYcY3KPxo2hYkXCYqdw9iwsWOB2\nIN9hhT6bLZyfSIfE2Zy5oYNNG2hMZhKBHj0os24uZYuc5bvv3A7kO6zQZ7P1X2+gLIcpNdCabYzJ\ndL16IbGxDGs4i6lTIT7e7UC+wQp9NlKFgLlOd4CgrtZ/3phM16oVlClD74RJHD9ug5xdZIU+G23e\nDK1PTedISDMoW9btOMbkPgEB0KsX5df9SKkC55g82e1AvsEKfTaa/+0hmrOSfLd2czuKMblXnz7I\nuXM803AWU6ZAQoLbgdxnhT4bnR7vNNsUGxThchJjcrE2bSA4mD46kcOHYdkytwO5zwp9Njl4EOr+\nPp2o4pWgng3Rb0yWCQiA3r2puOFHigedY9IktwO5zwp9Npk+MYaOzCWhSzcbrdKYrJak+WbSJGu+\nsUKfTfZ/uYCCxFBysDXbGJPl2rSBMmXo7zeBQ4es941XhV5EwkRkm4jsFJFhKaxvIyK/iki8iNya\nbN1gEdnh+RmcWcFzkpMnodKG6ZwPKgxt27odx5jcLyAA+vShwrrpXFvoNOPGuR3IXakWehHxBz4A\nOgO1gf4iUjvZZvuAO4GxyfYtCQwHbgCaAcNFJM8N1zhjWgI9dArRrTtDvnxuxzEmbxgwAImNZXj9\nKXz3HVy44HYg93hzRt8M2Kmqu1X1AjAe6J50A1Xdo6obgMRk+3YCflLVE6p6EvgJyHO3hG4dvYRr\nOEKJIX3cjmJM3tG8OVx3Hb1iv+XkSZg71+1A7vGm0JcH9id5fsCzzBte7SsiQ0UkUkQijx496uVL\n5wynT0O5pZO5EFAAv/DObscxJu8Qgdtvp/T6+dQsfihPN9/4xMVYVR2lqqGqGhocHOx2nEw1dUoi\nPRK/40zLzlC4sNtxjMlbbr8dSUzkhVoTmDoVzp51O5A7vCn0B4GKSZ5X8CzzRkb2zRU2fLKccvxJ\niSG3pr6xMSZz1aoFjRrR5eS3nD0L33/vdiB3eFPoVwPVRKSKiAQB/QBvp9+dA3QUkRKei7AdPcvy\nhBMnoMKKycT558OvW7jbcYzJmwYOpMjW1XSosIUxY9wO445UC72qxgMP4RToLcBEVd0kIiNEJAJA\nRJqKyAGgD/CJiGzy7HsCeAnny2I1MMKzLE/4fnIivXQyZ1t1gqJF3Y5jTN40YAAEBPBC5S9YsMCZ\nszmv8aqNXlVnqmp1Va2qqq94lj2vqtM8j1eragVVLaSqpVS1TpJ9P1fV6z0/X2TN2/BNG0ctoyIH\nKHaP9bYxxjXXXANdu3LDtq8III6vvnI7UPbziYuxudGff0LtNV9zIbAg0rOH23GMydvuvhv/Y4d5\nut4sxoxx5obIS6zQZ5FxX8TSh4nEhPWy3jbGuK1zZyhblqGBn7N7Nyxe7Hag7GWFPguowt6PZlKC\nUxR7cKDbcYwxAQFwxx1U3DCD6wod5rPP3A6UvazQZ4HVq+GmA19zrmhZaN/e7TjGGIC77kLi4/lv\nvTFMnAjHj7sdKPtYoc8CEz46QTgz8B/Y3zmTMMa4r2ZNuOkmuuz7mLjzCXmqq6UV+kwWGws6fgJB\nxJHv3kFuxzHGJPXAAwT9sYcnas3mk08gMfnoXLmUFfpM9sMUZVDsKM5UbQANG7odxxiTVI8ecO21\nPBb4ATt2wMKFbgfKHlboM9nCNyJpxDoKPX6fzSRljK8JDIShQyn322yaFN/FRx+5HSh7WKHPRBs3\nQtO1n3AhsCB+A293O44xJiVDhyJ+frxV7SOmTIE9e9wOlPWs0Gei0W9F0Z9xJN7WH4oVczuOMSYl\n5cpB79602vYZReUM777rdqCsZ4U+k0RFgX47lkKcI/+j97kdxxhzNf/8J36no3i/wad89pnz/zc3\ns0KfSb4co9x94SPO1WgEoaFuxzHGXE2zZtC2LX0OvkNsdByffup2oKxlhT4TJCbC2jfmUZ/fKPj0\nw3YR1pic4MknCTq8nxdqTuDddyEuzu1AWccKfSaYOhX6HvwvMcXLwu12EdaYHKFzZ6hdm4dj3+DA\nAeXbb90OlHWs0GeQKkx8fiNhzCHoiYcgXz63IxljvOHnB08+SdE9G3ikyo+8/DLEx7sdKmtYoc+g\nn3+GDhvfIi6wAP4P3O92HGNMWgwYANddx4synF27lLFj3Q6UNazQZ9Anw/9gIN8gd98FpUq5HccY\nkxaBgfD88xTfvZbHQqby0ku586zeq0IvImEisk1EdorIsBTW5xORCZ71K0UkxLM8RERiRGSd5+fj\nzI3vrshIuHHxSAL8Egl48gm34xhj0mPAAKhenRcYzq6dibnyrD7VQi8i/sAHQGegNtBfRGon2+we\n4KSqXg+8DbyWZN0uVW3o+clVbRtv//MA9/EJ8QPuhKpV3Y5jjEmPgAAYPpxiezbwVJXJPP+8Mzhh\nbuLNGX0zYKeq7lbVC8B4oHuybboDX3oeTwbai+TuPoYLFkDLX14lwF8JGvEft+MYYzKib1+oW5fh\nsc/w597zue5uWW8KfXlgf5LnBzzLUtxGVeOBKOBig3UVEVkrIotEpHVKBxCRoSISKSKRR48eTdMb\ncIMqvPvEXu7lM/TueyAkxO1IxpiM8PeHt96iwJ+7+ajWe7z6KuSAUuS1rL4Y+ydQSVUbAU8AY0Wk\naPKNVHWUqoaqamhwcHAWR8q4KVOg5/rh+AcIAc8/63YcY0xm6NABunZl8L6XKBR9mBdecDtQ5vGm\n0B8EKiZ5XsGzLMVtRCQAKAYcV9XzqnocQFXXALuA6hkN7abYWPj2kZXcyZfI449DhQpuRzLGZJY3\n38T/fAyTaj7HJ5/A2rVuB8oc3hT61UA1EakiIkFAP2Basm2mAYM9j28FFqiqikiw52IuInIdUA3Y\nnTnR3fHa/yXy1MFHOF/yWvyes7N5Y3KVGjXg4Ye5cctndC66lCFDICHB7VAZl2qh97S5PwTMAbYA\nE1V1k4iMEJEIz2ajgVIishOnieZiF8w2wAYRWYdzkfZ+VT2R2W8iu+zcCftf/ZobWEW+t0dCkSJu\nRzLGZLYRI5BKlfi2wL1sXBPL//7ndqCME1V1O8NlQkNDNTIy0u0Yf6MKt91ygvcX1qZEoxCCVi9z\nbqE2xuQ+c+ZAWBjjqz7LvYdeZtMmqFzZ7VBXJyJrVDXFoXOtUnlpzBjoseBhSstxgkZ/bEXemNys\nUye44w767n2Nhom/cscdObsJx6qVF3btgnkPfM8AxiLPPWeTfhuTF7z9NnLNNcws2pdffznDq6+6\nHSj9rNCnIj4eHu53lHfO38+FOo3we/YZtyMZY7JDyZIwbhxFj+5mTsj9vDBcWbrU7VDpY4U+FS8+\nF88Tkf0pGXCaoHFfOoMgGWPyhtat4YUXuHHPWJ4uPZq+feGPP9wOlXZW6K9iwgQoNPI/3MJ8/D/+\nEOrVczuSMSa7/fvf0KEDL598gHrHf6Z7dzh3zu1QaWOF/grWrIEf7viOYbxGwj1D4e673Y5kjHGD\nvz9MnIhfteuZGtCLM5HbuPNOZwrRnMIKfQp27YJXOv3CF3EDiWt8A/4fvOd2JGOMm4oXhxkzCCoQ\nwIqSXVg66SAPPeR0u84JrNAns3cvPNxqLWNOdIOQEALn/GjTAxpjoEoV+PFHisUdZX3xm5j60UEe\nfTRnFHsr9Ens3QsPtVzLl4c7kf+a4uRfNBdKl3Y7ljHGVzRrhsyZQ6mEw6wrfhNT/refBx/0/Vmp\nrNB7rF4N/2o4j7EH21D0mgIELfoJKlZMfUdjTN7SogUyZw6lE4+wqVAzIj9aRY8eEB3tdrArs0IP\nTJqofNHyM7491YXA6lXIF7kMqufoQTaNMVmpRQtk+XKKlinAssC2FJ85lpYtYetWt4OlLE8X+uho\neHDQaeL6DuDDuCFom7bkX/kLlE8+r4oxxiRTuzasXElA86Z8owN4dusgbm50ilGjfK/dPk8WelX4\ncbryr2pTefKb+vSTCcS/+DL5Fsx2rq4bY4w3goOdeUVffJE+CeNYr/WYf98E2rdTfvvN7XB/yXOF\nftUqeLj5avwiwvn4UA+CqxTGb/EvzkxR/v5uxzPG5DQBAfD888iyZQTXLMUE+vF/S1rxaIOfGTpE\n2bnT7YB5pNBHR8OEL2N5puYUztzQnvdXNaNdgeUkvPk2hbathZYt3Y5ojMnpmjVD1qyBTz+lacld\nLNCbuX90KK9UG8Md3aP48Ue4cMGdaLlyPPoLF2DjhkQ2Td9N1PRfKLlhIeEJ0yjGaaKLlSPgqSfI\n//BQmzjEGJM1YmLgm2+If/0tAnZu5TxBzCaMFQXb49emFVUi6nFj20Cuvx6CgjLnkFcbjz7XFPrD\nh6FPH+i7bhhtz/xIVXZRgFgAzuQvzdm2XQh+dAD+Hdo5v2oZY0xWS0yElStJGDeR8xOmUPDIXgDi\n8WcfldhLZRILFiahQGHmh9xL4s3teeON9B3qaoU+11S8YsVABCqF+BFw4Xr2Xh9GmdY1KNmtJUVq\n1aKIiNsRjTF5jZ8ftGiBf4sWFHzvbdi3D12ylFNLNiPrdnHdgf0kRh8kMCaaX6J6sO9w1sTw6oxe\nRMKAdwF/4DNVHZlsfT7gK6AJcBzoq6p7POueAe4BEoBHVHXO1Y7lq1MJGmOML8vQVIIi4g98AHQG\nagP9RaR2ss3uAU6q6vXA28Brnn1rA/2AOkAY8KHn9YwxxmQTb3rdNAN2qupuVb0AjAe6J9umO/Cl\n5/FkoL2IiGf5eFU9r6q/Azs9r2eMMSabeNNGXx7Yn+T5AeCGK22jqvEiEgWU8ixfkWzfv912KiJD\ngaGep9Eiss2r9JmvNHDMpWP7Ivs8/s4+k8vZ5/F3bn0mla+0wicuxqrqKGCU2zlEJPJKbVx5kX0e\nf2efyeXs8/g7X/xMvGm6OQgkHcaxgmdZituISABQDOeirDf7GmOMyULeFPrVQDURqSIiQTgXV6cl\n22YaMNjz+FZggTrdeaYB/UQkn4hUAaoBqzInujHGGG+k2nTjaXN/CJiD073yc1XdJCIjgEhVnQaM\nBr4WkZ3ACZwvAzzbTQQ2A/HAg6qakEXvJTO43nzkY+zz+Dv7TC5nn8ff+dxn4nN3xhpjjMlceWJQ\nM2OMycus0BtjTC5nhT4ZEekjIptEJFFEfKqLVHYSkTAR2SYiO0VkmNt53CYin4vIERHZ6HYWXyAi\nFUVkoYhs9vx/edTtTG4SkfwiskpE1ns+jxfdzpSUFfq/2wj0An5xO4hbvBz2Iq8ZgzOMh3HEA/9U\n1dpAc+DBPP5v5DzQTlUbAA2BMBFp7nKmS6zQJ6OqW1TVrTtzfYU3w17kKar6C06PMgOo6p+q+qvn\n8RlgCync9Z5XqCPa8zTQ8+MzPV2s0JuUpDTsRZ79T2yuTkRCgEbASneTuEtE/EVkHXAE+ElVfebz\n8IkhELKbiMwDyqaw6llVnZrdeYzJqUSkMPAd8JiqnnY7j5s89wg1FJHiwBQRqauqPnFNJ08WelW9\nxe0MPs6GrjCpEpFAnCL/rap+73YeX6Gqp0RkIc41HZ8o9NZ0Y1LizbAXJg/zDEM+Gtiiqm+5ncdt\nIhLsOZNHRAoAHYCt7qb6ixX6ZESkp4gcAFoAM0TkqjNi5UaqGg9cHPZiCzBRVTe5m8pdIjIOWA7U\nEJEDInKP25lc1hIYBLQTkXWeny5uh3LRtcBCEdmAc6L0k6r+6HKmS2wIBGOMyeXsjN4YY3I5K/TG\nGJPLWaE3xphczgq9McbkclbojTEml7NCb4wxuZwVemOMyeX+H+F8CMoO0MAwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAStoltl3jHi",
        "colab_type": "text"
      },
      "source": [
        "##Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOWwC3lm3lvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('FirstKearsmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2JyS5j13xje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "my_new_model = load_model('FirstKearsmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jmc_Ky54Y0R",
        "colab_type": "text"
      },
      "source": [
        "##Predict on new unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4l70k784Nwl",
        "colab_type": "code",
        "outputId": "129b93bf-1fc5-401d-b537-3c9f1ed28730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_new_model.predict_classes(X_train_scaled)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0,\n",
              "       2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2,\n",
              "       2, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2,\n",
              "       1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 1, 0, 2, 0, 1, 2, 2,\n",
              "       1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOaDJHo34ckm",
        "colab_type": "text"
      },
      "source": [
        "##Recurrent Neural Network\n",
        "\n",
        "Specifically designed to work with sequence data\n",
        "\n",
        "* Normal feed forward network :\n",
        "input --> aggregation --> activation function ---> output\n",
        "\n",
        "* Recurrent Neural Network :\n",
        "input --> aggregation --> activation function ---> output ---> feed back to input\n",
        "\n",
        "* Cells that are a function of inputs from previous time steps are known as memory cells\n",
        "\n",
        "* RNN are also flexible in their inputs and outputs for both sequences and single vector values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2tNRYWbBHt4",
        "colab_type": "text"
      },
      "source": [
        "## LSTMs GRU  and Text Generation\n",
        "\n",
        "* The issue with RNN is that after a while the network will begin to forget the first input as information is lost at each step  going through the RNN.\n",
        "\n",
        "The LSTM(Long Term Short Term Memory) helps to address the above issue.\n",
        "\n",
        "\n",
        "## Text Generation with LSTM using KERAS\n",
        "\n",
        "* Process Text\n",
        "* Clean Text\n",
        "* Tokenize the Text and create Sequences with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAEO80pU4fdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_files(filepath):\n",
        "  with open(filepath,'r') as f:\n",
        "    str_text = f.read()\n",
        "  return str_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNm5ajeJG7dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " text = read_files('/content/moby_dick_four_chapters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhQZ0E3NHGeH",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize and Clean the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgSunjvcHKQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en',disable=['parser','tagger','ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-kQv7U6HzXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp.max_length = 1198623"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mqOkcmaI8RH",
        "colab_type": "text"
      },
      "source": [
        "## Separate Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNgcgSECI70e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "punc_set = list(string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz177UP3KRDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punc_list = punc_set + [\"\\n\",\"\\n\\n\",\"\\n\\n\\n\",\"--\",\"\\t\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrbDKyS7L8e3",
        "colab_type": "code",
        "outputId": "7a13c2a9-0c33-4f6c-c28c-22a85db0e7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "punc_list"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " '\\n',\n",
              " '\\n\\n',\n",
              " '\\n\\n\\n',\n",
              " '--',\n",
              " '\\t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuvH3z0QKcGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sep_punc(doc_text):\n",
        "  return [token.text.lower() for token in nlp(doc_text) if token.text not in punc_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVG0PqphLLHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = read_files('/content/moby_dick_four_chapters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6EsOC5kLZdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = sep_punc(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbMxesfcLlqS",
        "colab_type": "code",
        "outputId": "548848c1-4dbb-4dc8-b329-1b5a027c8ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvi2GiRZMtP2",
        "colab_type": "text"
      },
      "source": [
        "##Create Sequence of Tokens\n",
        "\n",
        "i.e. pass fisrt 24 words of the sequence to the model and predict the 25th word in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84QjznnvM-jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize into sequence of tokens\n",
        "train_len = 50 + 1 # 50 training words , then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len,len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN5iciVxQX4g",
        "colab_type": "code",
        "outputId": "9ba2f8af-79bf-4803-da59-80e3c4180c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "text_sequences[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call',\n",
              " 'me',\n",
              " 'ishmael',\n",
              " ' ',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and',\n",
              " 'nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me',\n",
              " 'on',\n",
              " 'shore',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'i',\n",
              " 'would',\n",
              " 'sail',\n",
              " 'about',\n",
              " 'a',\n",
              " 'little',\n",
              " 'and',\n",
              " 'see',\n",
              " 'the',\n",
              " 'watery',\n",
              " 'part',\n",
              " 'of',\n",
              " 'the',\n",
              " 'world',\n",
              " ' ',\n",
              " 'it',\n",
              " 'is',\n",
              " 'a',\n",
              " 'way',\n",
              " 'i',\n",
              " 'have']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeuvsDPSQeI2",
        "colab_type": "code",
        "outputId": "9528fcd2-a7f3-49df-9dfc-5f5d667443b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "text_sequences[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['me',\n",
              " 'ishmael',\n",
              " ' ',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and',\n",
              " 'nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me',\n",
              " 'on',\n",
              " 'shore',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'i',\n",
              " 'would',\n",
              " 'sail',\n",
              " 'about',\n",
              " 'a',\n",
              " 'little',\n",
              " 'and',\n",
              " 'see',\n",
              " 'the',\n",
              " 'watery',\n",
              " 'part',\n",
              " 'of',\n",
              " 'the',\n",
              " 'world',\n",
              " ' ',\n",
              " 'it',\n",
              " 'is',\n",
              " 'a',\n",
              " 'way',\n",
              " 'i',\n",
              " 'have',\n",
              " 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqsz9h2aQnCl",
        "colab_type": "code",
        "outputId": "cbe450d2-a448-44ef-b206-f14df907cdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael   some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and see the watery part of the world   it is a way i have'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7HOSoeQRNrp",
        "colab_type": "code",
        "outputId": "87b1361e-bb69-4c77-e0b6-b28c5893f79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text_sequences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl_sIJw5Qw9A",
        "colab_type": "code",
        "outputId": "59ee1850-d43b-4cb4-8bab-c57216bb4347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me ishmael   some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and see the watery part of the world   it is a way i have of'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-4P9tXORF12",
        "colab_type": "code",
        "outputId": "d4cc7c1d-afc1-4054-e01d-a379c618ab31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ishmael   some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and see the watery part of the world   it is a way i have of driving'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "142NUn_MSG92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEsYgDcnT4tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lQFDyYUd_Y",
        "colab_type": "code",
        "outputId": "52ffa73e-2425-400d-fafb-25450ca8aa42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
        "sequences[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[956,\n",
              " 15,\n",
              " 262,\n",
              " 4,\n",
              " 51,\n",
              " 261,\n",
              " 408,\n",
              " 88,\n",
              " 219,\n",
              " 130,\n",
              " 121,\n",
              " 954,\n",
              " 260,\n",
              " 53,\n",
              " 44,\n",
              " 39,\n",
              " 315,\n",
              " 8,\n",
              " 24,\n",
              " 546,\n",
              " 3,\n",
              " 150,\n",
              " 259,\n",
              " 7,\n",
              " 2711,\n",
              " 15,\n",
              " 26,\n",
              " 2710,\n",
              " 6,\n",
              " 61,\n",
              " 6,\n",
              " 60,\n",
              " 406,\n",
              " 38,\n",
              " 2,\n",
              " 53,\n",
              " 3,\n",
              " 102,\n",
              " 1,\n",
              " 2709,\n",
              " 176,\n",
              " 5,\n",
              " 1,\n",
              " 175,\n",
              " 4,\n",
              " 9,\n",
              " 21,\n",
              " 2,\n",
              " 110,\n",
              " 6,\n",
              " 48]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwbRIomMU_oZ",
        "colab_type": "code",
        "outputId": "06d994bf-34a5-4115-d144-e5f382ec2fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "for i in sequences[0]:\n",
        "  print(f\"{i}:{tokenizer.index_word[i]}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "956:call\n",
            "15:me\n",
            "262:ishmael\n",
            "4: \n",
            "51:some\n",
            "261:years\n",
            "408:ago\n",
            "88:never\n",
            "219:mind\n",
            "130:how\n",
            "121:long\n",
            "954:precisely\n",
            "260:having\n",
            "53:little\n",
            "44:or\n",
            "39:no\n",
            "315:money\n",
            "8:in\n",
            "24:my\n",
            "546:purse\n",
            "3:and\n",
            "150:nothing\n",
            "259:particular\n",
            "7:to\n",
            "2711:interest\n",
            "15:me\n",
            "26:on\n",
            "2710:shore\n",
            "6:i\n",
            "61:thought\n",
            "6:i\n",
            "60:would\n",
            "406:sail\n",
            "38:about\n",
            "2:a\n",
            "53:little\n",
            "3:and\n",
            "102:see\n",
            "1:the\n",
            "2709:watery\n",
            "176:part\n",
            "5:of\n",
            "1:the\n",
            "175:world\n",
            "4: \n",
            "9:it\n",
            "21:is\n",
            "2:a\n",
            "110:way\n",
            "6:i\n",
            "48:have\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3jmheZ-YKtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d71c7c9-9ee5-4738-f0cc-4c0eb7980f8e"
      },
      "source": [
        "tokenizer.word_counts"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('call', 52),\n",
              "             ('me', 4822),\n",
              "             ('ishmael', 258),\n",
              "             (' ', 16624),\n",
              "             ('some', 1484),\n",
              "             ('years', 261),\n",
              "             ('ago', 160),\n",
              "             ('never', 875),\n",
              "             ('mind', 315),\n",
              "             ('how', 613),\n",
              "             ('long', 712),\n",
              "             ('precisely', 63),\n",
              "             ('having', 268),\n",
              "             ('little', 1478),\n",
              "             ('or', 1851),\n",
              "             ('no', 1954),\n",
              "             ('money', 221),\n",
              "             ('in', 11048),\n",
              "             ('my', 3487),\n",
              "             ('purse', 122),\n",
              "             ('and', 18850),\n",
              "             ('nothing', 532),\n",
              "             ('particular', 278),\n",
              "             ('to', 12723),\n",
              "             ('interest', 25),\n",
              "             ('on', 3342),\n",
              "             ('shore', 28),\n",
              "             ('i', 13982),\n",
              "             ('thought', 1305),\n",
              "             ('would', 1358),\n",
              "             ('sail', 186),\n",
              "             ('about', 1972),\n",
              "             ('a', 20329),\n",
              "             ('see', 803),\n",
              "             ('the', 30413),\n",
              "             ('watery', 40),\n",
              "             ('part', 449),\n",
              "             ('of', 16204),\n",
              "             ('world', 452),\n",
              "             ('it', 8308),\n",
              "             ('is', 3815),\n",
              "             ('way', 763),\n",
              "             ('have', 1581),\n",
              "             ('driving', 51),\n",
              "             ('off', 816),\n",
              "             ('spleen', 51),\n",
              "             ('regulating', 51),\n",
              "             ('circulation', 51),\n",
              "             ('whenever', 255),\n",
              "             ('find', 153),\n",
              "             ('myself', 816),\n",
              "             ('growing', 51),\n",
              "             ('grim', 51),\n",
              "             ('mouth', 255),\n",
              "             ('damp', 153),\n",
              "             ('drizzly', 51),\n",
              "             ('november', 51),\n",
              "             ('soul', 153),\n",
              "             ('involuntarily', 102),\n",
              "             ('pausing', 102),\n",
              "             ('before', 714),\n",
              "             ('coffin', 204),\n",
              "             ('warehouses', 102),\n",
              "             ('bringing', 51),\n",
              "             ('up', 2412),\n",
              "             ('rear', 51),\n",
              "             ('every', 357),\n",
              "             ('funeral', 51),\n",
              "             ('meet', 51),\n",
              "             ('especially', 204),\n",
              "             ('hypos', 51),\n",
              "             ('get', 714),\n",
              "             ('such', 1122),\n",
              "             ('an', 1581),\n",
              "             ('upper', 51),\n",
              "             ('hand', 612),\n",
              "             ('that', 7395),\n",
              "             ('requires', 102),\n",
              "             ('strong', 153),\n",
              "             ('moral', 51),\n",
              "             ('principle', 51),\n",
              "             ('prevent', 51),\n",
              "             ('from', 2958),\n",
              "             ('deliberately', 51),\n",
              "             ('stepping', 51),\n",
              "             ('into', 1938),\n",
              "             ('street', 204),\n",
              "             ('methodically', 51),\n",
              "             ('knocking', 51),\n",
              "             ('people', 102),\n",
              "             (\"'s\", 3316),\n",
              "             ('hats', 51),\n",
              "             ('then', 1632),\n",
              "             ('account', 153),\n",
              "             ('high', 255),\n",
              "             ('time', 1020),\n",
              "             ('sea', 1071),\n",
              "             ('as', 4641),\n",
              "             ('soon', 434),\n",
              "             ('can', 663),\n",
              "             ('this', 4233),\n",
              "             ('substitute', 51),\n",
              "             ('for', 3570),\n",
              "             ('pistol', 51),\n",
              "             ('ball', 51),\n",
              "             ('with', 4692),\n",
              "             ('philosophical', 51),\n",
              "             ('flourish', 51),\n",
              "             ('cato', 51),\n",
              "             ('throws', 51),\n",
              "             ('himself', 663),\n",
              "             ('upon', 1530),\n",
              "             ('his', 6117),\n",
              "             ('sword', 153),\n",
              "             ('quietly', 153),\n",
              "             ('take', 510),\n",
              "             ('ship', 357),\n",
              "             ('there', 2856),\n",
              "             ('surprising', 51),\n",
              "             ('if', 1428),\n",
              "             ('they', 1428),\n",
              "             ('but', 5202),\n",
              "             ('knew', 255),\n",
              "             ('almost', 561),\n",
              "             ('all', 3672),\n",
              "             ('men', 255),\n",
              "             ('their', 765),\n",
              "             ('degree', 153),\n",
              "             ('other', 969),\n",
              "             ('cherish', 51),\n",
              "             ('very', 969),\n",
              "             ('nearly', 102),\n",
              "             ('same', 612),\n",
              "             ('feelings', 51),\n",
              "             ('towards', 510),\n",
              "             ('ocean', 102),\n",
              "             ('now', 2040),\n",
              "             ('your', 867),\n",
              "             ('insular', 51),\n",
              "             ('city', 204),\n",
              "             ('manhattoes', 51),\n",
              "             ('belted', 51),\n",
              "             ('round', 714),\n",
              "             ('by', 1887),\n",
              "             ('wharves', 51),\n",
              "             ('indian', 102),\n",
              "             ('isles', 51),\n",
              "             ('coral', 51),\n",
              "             ('reefs', 51),\n",
              "             ('commerce', 51),\n",
              "             ('surrounds', 51),\n",
              "             ('her', 306),\n",
              "             ('surf', 51),\n",
              "             ('right', 306),\n",
              "             ('left', 153),\n",
              "             ('streets', 408),\n",
              "             ('you', 4233),\n",
              "             ('waterward', 102),\n",
              "             ('its', 306),\n",
              "             ('extreme', 51),\n",
              "             ('downtown', 51),\n",
              "             ('battery', 102),\n",
              "             ('where', 714),\n",
              "             ('noble', 102),\n",
              "             ('mole', 51),\n",
              "             ('washed', 102),\n",
              "             ('waves', 51),\n",
              "             ('cooled', 51),\n",
              "             ('breezes', 51),\n",
              "             ('which', 1122),\n",
              "             ('few', 204),\n",
              "             ('hours', 255),\n",
              "             ('previous', 204),\n",
              "             ('were', 1887),\n",
              "             ('out', 1856),\n",
              "             ('sight', 204),\n",
              "             ('land', 408),\n",
              "             ('look', 306),\n",
              "             ('at', 4284),\n",
              "             ('crowds', 102),\n",
              "             ('water', 459),\n",
              "             ('gazers', 51),\n",
              "             ('circumambulate', 51),\n",
              "             ('dreamy', 51),\n",
              "             ('sabbath', 102),\n",
              "             ('afternoon', 102),\n",
              "             ('go', 969),\n",
              "             ('corlears', 51),\n",
              "             ('hook', 51),\n",
              "             ('coenties', 51),\n",
              "             ('slip', 51),\n",
              "             ('thence', 102),\n",
              "             ('whitehall', 51),\n",
              "             ('northward', 51),\n",
              "             ('what', 2193),\n",
              "             ('do', 1377),\n",
              "             ('see?--posted', 51),\n",
              "             ('like', 1432),\n",
              "             ('silent', 102),\n",
              "             ('sentinels', 51),\n",
              "             ('around', 153),\n",
              "             ('town', 306),\n",
              "             ('stand', 357),\n",
              "             ('thousands', 102),\n",
              "             ('mortal', 51),\n",
              "             ('fixed', 153),\n",
              "             ('reveries', 102),\n",
              "             ('leaning', 102),\n",
              "             ('against', 459),\n",
              "             ('spiles', 51),\n",
              "             ('seated', 102),\n",
              "             ('pier', 51),\n",
              "             ('heads', 663),\n",
              "             ('looking', 612),\n",
              "             ('over', 1377),\n",
              "             ('bulwarks', 102),\n",
              "             ('ships', 153),\n",
              "             ('china', 51),\n",
              "             ('aloft', 102),\n",
              "             ('rigging', 51),\n",
              "             ('striving', 51),\n",
              "             ('still', 714),\n",
              "             ('better', 408),\n",
              "             ('seaward', 51),\n",
              "             ('peep', 51),\n",
              "             ('these', 969),\n",
              "             ('are', 800),\n",
              "             ('landsmen', 51),\n",
              "             ('week', 102),\n",
              "             ('days', 204),\n",
              "             ('pent', 51),\n",
              "             ('lath', 51),\n",
              "             ('plaster', 102),\n",
              "             ('tied', 51),\n",
              "             ('counters', 51),\n",
              "             ('nailed', 51),\n",
              "             ('benches', 51),\n",
              "             ('clinched', 51),\n",
              "             ('desks', 51),\n",
              "             ('green', 255),\n",
              "             ('fields', 51),\n",
              "             ('gone', 102),\n",
              "             ('here', 1173),\n",
              "             ('come', 663),\n",
              "             ('more', 969),\n",
              "             ('pacing', 51),\n",
              "             ('straight', 190),\n",
              "             ('seemingly', 51),\n",
              "             ('bound', 102),\n",
              "             ('dive', 51),\n",
              "             ('strange', 357),\n",
              "             ('will', 510),\n",
              "             ('content', 102),\n",
              "             ('them', 867),\n",
              "             ('extremest', 51),\n",
              "             ('limit', 51),\n",
              "             ('loitering', 51),\n",
              "             ('under', 510),\n",
              "             ('shady', 51),\n",
              "             ('lee', 51),\n",
              "             ('yonder', 102),\n",
              "             ('not', 3009),\n",
              "             ('suffice', 51),\n",
              "             ('must', 867),\n",
              "             ('just', 765),\n",
              "             ('nigh', 204),\n",
              "             ('possibly', 51),\n",
              "             ('without', 357),\n",
              "             ('falling', 102),\n",
              "             ('miles', 153),\n",
              "             ('leagues', 51),\n",
              "             ('inlanders', 51),\n",
              "             ('lanes', 51),\n",
              "             ('alleys', 51),\n",
              "             ('avenues', 51),\n",
              "             ('north', 102),\n",
              "             ('east', 51),\n",
              "             ('south', 306),\n",
              "             ('west', 51),\n",
              "             ('yet', 816),\n",
              "             ('unite', 51),\n",
              "             ('tell', 867),\n",
              "             ('does', 306),\n",
              "             ('magnetic', 51),\n",
              "             ('virtue', 51),\n",
              "             ('needles', 51),\n",
              "             ('compasses', 51),\n",
              "             ('those', 459),\n",
              "             ('attract', 51),\n",
              "             ('thither', 51),\n",
              "             ('once', 408),\n",
              "             ('say', 561),\n",
              "             ('country', 153),\n",
              "             ('lakes', 51),\n",
              "             ('any', 714),\n",
              "             ('path', 51),\n",
              "             ('please', 102),\n",
              "             ('ten', 102),\n",
              "             ('one', 2550),\n",
              "             ('carries', 51),\n",
              "             ('down', 918),\n",
              "             ('dale', 51),\n",
              "             ('leaves', 102),\n",
              "             ('pool', 51),\n",
              "             ('stream', 153),\n",
              "             ('magic', 102),\n",
              "             ('let', 306),\n",
              "             ('most', 918),\n",
              "             ('absent', 51),\n",
              "             ('minded', 51),\n",
              "             ('be', 3366),\n",
              "             ('plunged', 102),\n",
              "             ('deepest', 51),\n",
              "             ('man', 1122),\n",
              "             ('legs', 204),\n",
              "             ('set', 306),\n",
              "             ('feet', 357),\n",
              "             ('going', 510),\n",
              "             ('he', 6347),\n",
              "             ('infallibly', 51),\n",
              "             ('lead', 153),\n",
              "             ('region', 51),\n",
              "             ('should', 561),\n",
              "             ('ever', 663),\n",
              "             ('athirst', 51),\n",
              "             ('great', 726),\n",
              "             ('american', 153),\n",
              "             ('desert', 51),\n",
              "             ('try', 204),\n",
              "             ('experiment', 51),\n",
              "             ('caravan', 51),\n",
              "             ('happen', 51),\n",
              "             ('supplied', 51),\n",
              "             ('metaphysical', 102),\n",
              "             ('professor', 51),\n",
              "             ('yes', 204),\n",
              "             ('knows', 51),\n",
              "             ('meditation', 51),\n",
              "             ('wedded', 51),\n",
              "             ('artist', 153),\n",
              "             ('desires', 51),\n",
              "             ('paint', 51),\n",
              "             ('dreamiest', 51),\n",
              "             ('shadiest', 51),\n",
              "             ('quietest', 51),\n",
              "             ('enchanting', 51),\n",
              "             ('bit', 255),\n",
              "             ('romantic', 51),\n",
              "             ('landscape', 51),\n",
              "             ('valley', 51),\n",
              "             ('saco', 51),\n",
              "             ('chief', 102),\n",
              "             ('element', 51),\n",
              "             ('employs', 51),\n",
              "             ('trees', 51),\n",
              "             ('each', 153),\n",
              "             ('hollow', 51),\n",
              "             ('trunk', 102),\n",
              "             ('hermit', 51),\n",
              "             ('crucifix', 51),\n",
              "             ('within', 255),\n",
              "             ('sleeps', 51),\n",
              "             ('meadow', 102),\n",
              "             ('sleep', 816),\n",
              "             ('cattle', 51),\n",
              "             ('cottage', 51),\n",
              "             ('goes', 153),\n",
              "             ('sleepy', 51),\n",
              "             ('smoke', 102),\n",
              "             ('deep', 153),\n",
              "             ('distant', 153),\n",
              "             ('woodlands', 51),\n",
              "             ('winds', 153),\n",
              "             ('mazy', 51),\n",
              "             ('reaching', 102),\n",
              "             ('overlapping', 51),\n",
              "             ('spurs', 51),\n",
              "             ('mountains', 51),\n",
              "             ('bathed', 51),\n",
              "             ('hill', 102),\n",
              "             ('side', 561),\n",
              "             ('blue', 153),\n",
              "             ('though', 969),\n",
              "             ('picture', 255),\n",
              "             ('lies', 51),\n",
              "             ('thus', 102),\n",
              "             ('tranced', 51),\n",
              "             ('pine', 102),\n",
              "             ('tree', 51),\n",
              "             ('shakes', 51),\n",
              "             ('sighs', 102),\n",
              "             ('shepherd', 102),\n",
              "             ('head', 1171),\n",
              "             ('vain', 51),\n",
              "             ('unless', 204),\n",
              "             ('eye', 51),\n",
              "             ('him', 2142),\n",
              "             ('visit', 51),\n",
              "             ('prairies', 51),\n",
              "             ('june', 102),\n",
              "             ('when', 1275),\n",
              "             ('scores', 102),\n",
              "             ('wade', 51),\n",
              "             ('knee', 51),\n",
              "             ('among', 153),\n",
              "             ('tiger', 51),\n",
              "             ('lilies', 51),\n",
              "             ('charm', 51),\n",
              "             ('wanting?--water', 51),\n",
              "             ('drop', 51),\n",
              "             ('niagara', 51),\n",
              "             ('cataract', 51),\n",
              "             ('sand', 51),\n",
              "             ('travel', 51),\n",
              "             ('thousand', 102),\n",
              "             ('why', 561),\n",
              "             ('did', 1122),\n",
              "             ('poor', 204),\n",
              "             ('poet', 51),\n",
              "             ('tennessee', 51),\n",
              "             ('suddenly', 153),\n",
              "             ('receiving', 51),\n",
              "             ('two', 663),\n",
              "             ('handfuls', 51),\n",
              "             ('silver', 51),\n",
              "             ('deliberate', 51),\n",
              "             ('whether', 357),\n",
              "             ('buy', 51),\n",
              "             ('coat', 204),\n",
              "             ('sadly', 102),\n",
              "             ('needed', 51),\n",
              "             ('invest', 51),\n",
              "             ('pedestrian', 51),\n",
              "             ('trip', 51),\n",
              "             ('rockaway', 51),\n",
              "             ('beach', 51),\n",
              "             ('robust', 102),\n",
              "             ('healthy', 102),\n",
              "             ('boy', 102),\n",
              "             ('crazy', 102),\n",
              "             ('first', 969),\n",
              "             ('voyage', 408),\n",
              "             ('passenger', 204),\n",
              "             ('yourself', 306),\n",
              "             ('feel', 153),\n",
              "             ('mystical', 51),\n",
              "             ('vibration', 51),\n",
              "             ('told', 255),\n",
              "             ('old', 1479),\n",
              "             ('persians', 51),\n",
              "             ('hold', 102),\n",
              "             ('holy', 102),\n",
              "             ('greeks', 51),\n",
              "             ('give', 408),\n",
              "             ('separate', 51),\n",
              "             ('deity', 51),\n",
              "             ('own', 561),\n",
              "             ('brother', 102),\n",
              "             ('jove', 51),\n",
              "             ('surely', 51),\n",
              "             ('meaning', 153),\n",
              "             ('deeper', 51),\n",
              "             ('story', 255),\n",
              "             ('narcissus', 51),\n",
              "             ('who', 816),\n",
              "             ('because', 357),\n",
              "             ('could', 1275),\n",
              "             ('grasp', 51),\n",
              "             ('tormenting', 51),\n",
              "             ('mild', 51),\n",
              "             ('image', 306),\n",
              "             ('saw', 306),\n",
              "             ('fountain', 51),\n",
              "             ('was', 5637),\n",
              "             ('drowned', 51),\n",
              "             ('we', 561),\n",
              "             ('ourselves', 102),\n",
              "             ('rivers', 51),\n",
              "             ('oceans', 51),\n",
              "             ('ungraspable', 51),\n",
              "             ('phantom', 153),\n",
              "             ('life', 153),\n",
              "             ('key', 51),\n",
              "             ('am', 306),\n",
              "             ('habit', 51),\n",
              "             ('begin', 102),\n",
              "             ('grow', 102),\n",
              "             ('hazy', 51),\n",
              "             ('eyes', 357),\n",
              "             ('conscious', 51),\n",
              "             ('lungs', 51),\n",
              "             ('mean', 255),\n",
              "             ('inferred', 102),\n",
              "             ('needs', 102),\n",
              "             ('rag', 51),\n",
              "             ('something', 612),\n",
              "             ('besides', 306),\n",
              "             ('passengers', 153),\n",
              "             ('sick', 51),\n",
              "             ('quarrelsome', 51),\n",
              "             (\"don't\", 102),\n",
              "             ('nights', 51),\n",
              "             ('enjoy', 51),\n",
              "             ('themselves', 102),\n",
              "             ('much', 867),\n",
              "             ('general', 51),\n",
              "             ('thing;--no', 51),\n",
              "             ('nor', 153),\n",
              "             ('salt', 51),\n",
              "             ('commodore', 102),\n",
              "             ('captain', 102),\n",
              "             ('cook', 102),\n",
              "             ('abandon', 51),\n",
              "             ('glory', 102),\n",
              "             ('distinction', 51),\n",
              "             ('offices', 51),\n",
              "             ('abominate', 51),\n",
              "             ('honourable', 51),\n",
              "             ('respectable', 51),\n",
              "             ('toils', 51),\n",
              "             ('trials', 51),\n",
              "             ('tribulations', 51),\n",
              "             ('kind', 153),\n",
              "             ('whatsoever', 102),\n",
              "             ('quite', 153),\n",
              "             ('care', 153),\n",
              "             ('taking', 204),\n",
              "             ('barques', 51),\n",
              "             ('brigs', 51),\n",
              "             ('schooners', 51),\n",
              "             ('cook,--though', 51),\n",
              "             ('confess', 102),\n",
              "             ('considerable', 51),\n",
              "             ('being', 765),\n",
              "             ('sort', 969),\n",
              "             ('officer', 102),\n",
              "             ('board', 153),\n",
              "             ('somehow', 153),\n",
              "             ('fancied', 51),\n",
              "             ('broiling', 51),\n",
              "             ('fowls;--though', 51),\n",
              "             ('broiled', 153),\n",
              "             ('judiciously', 51),\n",
              "             ('buttered', 51),\n",
              "             ('judgmatically', 51),\n",
              "             ('salted', 51),\n",
              "             ('peppered', 51),\n",
              "             ('speak', 255),\n",
              "             ('respectfully', 102),\n",
              "             ('reverentially', 51),\n",
              "             ('fowl', 51),\n",
              "             ('than', 765),\n",
              "             ('idolatrous', 51),\n",
              "             ('dotings', 51),\n",
              "             ('egyptians', 51),\n",
              "             ('ibis', 51),\n",
              "             ('roasted', 51),\n",
              "             ('river', 51),\n",
              "             ('horse', 102),\n",
              "             ('mummies', 51),\n",
              "             ('creatures', 51),\n",
              "             ('huge', 102),\n",
              "             ('bake', 51),\n",
              "             ('houses', 102),\n",
              "             ('pyramids', 51),\n",
              "             ('simple', 51),\n",
              "             ('sailor', 306),\n",
              "             ('mast', 153),\n",
              "             ('plumb', 51),\n",
              "             ('forecastle', 102),\n",
              "             ('royal', 51),\n",
              "             ('true', 204),\n",
              "             ('rather', 408),\n",
              "             ('order', 255),\n",
              "             ('make', 510),\n",
              "             ('jump', 102),\n",
              "             ('spar', 102),\n",
              "             ('grasshopper', 51),\n",
              "             ('may', 612),\n",
              "             ('thing', 204),\n",
              "             ('unpleasant', 51),\n",
              "             ('enough', 663),\n",
              "             ('touches', 51),\n",
              "             ('sense', 153),\n",
              "             ('honour', 51),\n",
              "             ('particularly', 102),\n",
              "             ('established', 51),\n",
              "             ('family', 51),\n",
              "             ('van', 51),\n",
              "             ('rensselaers', 51),\n",
              "             ('randolphs', 51),\n",
              "             ('hardicanutes', 51),\n",
              "             ('putting', 102),\n",
              "             ('tar', 102),\n",
              "             ('pot', 51),\n",
              "             ('been', 918),\n",
              "             ('lording', 51),\n",
              "             ('schoolmaster', 102),\n",
              "             ('making', 255),\n",
              "             ('tallest', 51),\n",
              "             ('boys', 102),\n",
              "             ('awe', 51),\n",
              "             ('transition', 102),\n",
              "             ('keen', 51),\n",
              "             ('assure', 51),\n",
              "             ('decoction', 51),\n",
              "             ('seneca', 51),\n",
              "             ('stoics', 51),\n",
              "             ('enable', 51),\n",
              "             ('grin', 102),\n",
              "             ('bear', 102),\n",
              "             ('even', 255),\n",
              "             ('wears', 51),\n",
              "             ('hunks', 102),\n",
              "             ('orders', 51),\n",
              "             ('broom', 51),\n",
              "             ('sweep', 102),\n",
              "             ('decks', 51),\n",
              "             ('indignity', 51),\n",
              "             ('amount', 51),\n",
              "             ('weighed', 102),\n",
              "             ('scales', 51),\n",
              "             ('new', 561),\n",
              "             ('testament', 51),\n",
              "             ('think', 357),\n",
              "             ('archangel', 51),\n",
              "             ('gabriel', 51),\n",
              "             ('thinks', 357),\n",
              "             ('anything', 102),\n",
              "             ('less', 102),\n",
              "             ('promptly', 51),\n",
              "             ('obey', 51),\n",
              "             ('instance', 51),\n",
              "             ('ai', 204),\n",
              "             (\"n't\", 1224),\n",
              "             ('slave', 51),\n",
              "             ('well', 408),\n",
              "             ('however', 408),\n",
              "             ('captains', 51),\n",
              "             ('thump', 102),\n",
              "             ('punch', 51),\n",
              "             ('satisfaction', 51),\n",
              "             ('knowing', 153),\n",
              "             ('everybody', 51),\n",
              "             ('else', 408),\n",
              "             ('served', 51),\n",
              "             ('either', 153),\n",
              "             ('physical', 51),\n",
              "             ('point', 102),\n",
              "             ('view', 102),\n",
              "             ('so', 2091),\n",
              "             ('universal', 51),\n",
              "             ('passed', 153),\n",
              "             ('hands', 153),\n",
              "             ('rub', 51),\n",
              "             ('shoulder', 51),\n",
              "             ('blades', 51),\n",
              "             ('again', 561),\n",
              "             ('always', 187),\n",
              "             ('paying', 153),\n",
              "             ('trouble', 51),\n",
              "             ('whereas', 51),\n",
              "             ('pay', 153),\n",
              "             ('single', 102),\n",
              "             ('penny', 153),\n",
              "             ('heard', 408),\n",
              "             ('contrary', 51),\n",
              "             ('difference', 102),\n",
              "             ('between', 459),\n",
              "             ('paid', 51),\n",
              "             ('act', 102),\n",
              "             ('perhaps', 255),\n",
              "             ('uncomfortable', 102),\n",
              "             ('infliction', 51),\n",
              "             ('orchard', 51),\n",
              "             ('thieves', 51),\n",
              "             ('entailed', 51),\n",
              "             ('us', 204),\n",
              "             ('paid,--what', 51),\n",
              "             ('compare', 102),\n",
              "             ('urbane', 51),\n",
              "             ('activity', 51),\n",
              "             ('receives', 51),\n",
              "             ('really', 204),\n",
              "             ('marvellous', 204),\n",
              "             ('considering', 51),\n",
              "             ('earnestly', 51),\n",
              "             ('believe', 51),\n",
              "             ('root', 51),\n",
              "             ('earthly', 102),\n",
              "             ('ills', 51),\n",
              "             ('monied', 51),\n",
              "             ('enter', 102),\n",
              "             ('heaven', 204),\n",
              "             ('ah', 51),\n",
              "             ('cheerfully', 51),\n",
              "             ('consign', 51),\n",
              "             ('perdition', 51),\n",
              "             ('finally', 51),\n",
              "             ('wholesome', 51),\n",
              "             ('exercise', 51),\n",
              "             ('pure', 51),\n",
              "             ('air', 204),\n",
              "             ('fore', 51),\n",
              "             ('castle', 51),\n",
              "             ('deck', 102),\n",
              "             ('far', 204),\n",
              "             ('prevalent', 51),\n",
              "             ('astern', 51),\n",
              "             ('violate', 51),\n",
              "             ('pythagorean', 51),\n",
              "             ('maxim', 51),\n",
              "             ('quarter', 102),\n",
              "             ('gets', 51),\n",
              "             ('atmosphere', 51),\n",
              "             ('second', 204),\n",
              "             ('sailors', 153),\n",
              "             ('breathes', 51),\n",
              "             ('commonalty', 51),\n",
              "             ('leaders', 102),\n",
              "             ('many', 204),\n",
              "             ('things', 255),\n",
              "             ('suspect', 51),\n",
              "             ('wherefore', 51),\n",
              "             ('after', 459),\n",
              "             ('repeatedly', 51),\n",
              "             ('smelt', 102),\n",
              "             ('merchant', 51),\n",
              "             ('whaling', 459),\n",
              "             ('invisible', 51),\n",
              "             ('police', 51),\n",
              "             ('fates', 102),\n",
              "             ('has', 204),\n",
              "             ('constant', 51),\n",
              "             ('surveillance', 51),\n",
              "             ('secretly', 51),\n",
              "             ('dogs', 51),\n",
              "             ('influences', 51),\n",
              "             ('unaccountable', 204),\n",
              "             ('answer', 255),\n",
              "             ('doubtless', 102),\n",
              "             ('formed', 102),\n",
              "             ('grand', 204),\n",
              "             ('programme', 51),\n",
              "             ('providence', 51),\n",
              "             ('drawn', 51),\n",
              "             ('came', 561),\n",
              "             ('brief', 51),\n",
              "             ('interlude', 51),\n",
              "             ('solo', 51),\n",
              "             ('extensive', 51),\n",
              "             ('performances', 51),\n",
              "             ('bill', 51),\n",
              "             ('run', 102),\n",
              "             ('contested', 51),\n",
              "             ('election', 51),\n",
              "             ('presidency', 51),\n",
              "             ('united', 51),\n",
              "             ('states', 51),\n",
              "             ('bloody', 51),\n",
              "             ('battle', 51),\n",
              "             ('affghanistan', 51),\n",
              "             ('exactly', 153),\n",
              "             ('stage', 102),\n",
              "             ('managers', 51),\n",
              "             ('put', 408),\n",
              "             ('shabby', 102),\n",
              "             ('others', 102),\n",
              "             ('magnificent', 51),\n",
              "             ('parts', 255),\n",
              "             ('tragedies', 51),\n",
              "             ('short', 153),\n",
              "             ('easy', 153),\n",
              "             ('genteel', 51),\n",
              "             ('comedies', 51),\n",
              "             ('jolly', 204),\n",
              "             ('farces', 51),\n",
              "             ('recall', 51),\n",
              "             ('circumstances', 102),\n",
              "             ('springs', 51),\n",
              "             ('motives', 102),\n",
              "             ('cunningly', 51),\n",
              "             ('presented', 51),\n",
              "             ('various', 102),\n",
              "             ('disguises', 51),\n",
              "             ('induced', 51),\n",
              "             ('performing', 51),\n",
              "             ('cajoling', 51),\n",
              "             ('delusion', 51),\n",
              "             ('choice', 51),\n",
              "             ('resulting', 51),\n",
              "             ('unbiased', 51),\n",
              "             ('freewill', 51),\n",
              "             ('discriminating', 51),\n",
              "             ('judgment', 51),\n",
              "             ('overwhelming', 51),\n",
              "             ('idea', 357),\n",
              "             ('whale', 510),\n",
              "             ('portentous', 153),\n",
              "             ('mysterious', 102),\n",
              "             ('monster', 51),\n",
              "             ('roused', 51),\n",
              "             ('curiosity', 102),\n",
              "             ('wild', 255),\n",
              "             ('seas', 306),\n",
              "             ('rolled', 306),\n",
              "             ('island', 153),\n",
              "             ('bulk', 51),\n",
              "             ('undeliverable', 51),\n",
              "             ('nameless', 153),\n",
              "             ('perils', 51),\n",
              "             ('attending', 51),\n",
              "             ('marvels', 51),\n",
              "             ('patagonian', 51),\n",
              "             ('sights', 51),\n",
              "             ('sounds', 153),\n",
              "             ('helped', 51),\n",
              "             ('sway', 51),\n",
              "             ('wish', 51),\n",
              "             ('inducements', 51),\n",
              "             ('tormented', 102),\n",
              "             ('everlasting', 102),\n",
              "             ('itch', 51),\n",
              "             ('remote', 51),\n",
              "             ('love', 51),\n",
              "             ('forbidden', 51),\n",
              "             ('barbarous', 51),\n",
              "             ('coasts', 51),\n",
              "             ('ignoring', 51),\n",
              "             ('good', 867),\n",
              "             ('quick', 51),\n",
              "             ('perceive', 51),\n",
              "             ('horror', 51),\n",
              "             ('social', 51),\n",
              "             ('since', 153),\n",
              "             ('friendly', 51),\n",
              "             ('terms', 51),\n",
              "             ('inmates', 51),\n",
              "             ('place', 765),\n",
              "             ('lodges', 51),\n",
              "             ('reason', 255),\n",
              "             ('welcome', 51),\n",
              "             ('flood', 51),\n",
              "             ('gates', 51),\n",
              "             ('wonder', 102),\n",
              "             ('swung', 51),\n",
              "             ('open', 204),\n",
              "             ('conceits', 51),\n",
              "             ('swayed', 51),\n",
              "             ('purpose', 102),\n",
              "             ('floated', 102),\n",
              "             ('inmost', 51),\n",
              "             ('endless', 51),\n",
              "             ('processions', 51),\n",
              "             ('mid', 51),\n",
              "             ('hooded', 51),\n",
              "             ('snow', 153),\n",
              "             ('stuffed', 102),\n",
              "             ('shirt', 204),\n",
              "             ('carpet', 51),\n",
              "             ('bag', 357),\n",
              "             ('tucked', 51),\n",
              "             ('arm', 561),\n",
              "             ('started', 51),\n",
              "             ('cape', 204),\n",
              "             ('horn', 102),\n",
              "             ('pacific', 51),\n",
              "             ('quitting', 51),\n",
              "             ('manhatto', 51),\n",
              "             ('duly', 51),\n",
              "             ('arrived', 102),\n",
              "             ('bedford', 204),\n",
              "             ('saturday', 153),\n",
              "             ('night', 1224),\n",
              "             ('december', 51),\n",
              "             ('disappointed', 51),\n",
              "             ('learning', 51),\n",
              "             ('packet', 51),\n",
              "             ('nantucket', 357),\n",
              "             ('had', 1683),\n",
              "             ('already', 51),\n",
              "             ('sailed', 51),\n",
              "             ('offer', 102),\n",
              "             ('till', 306),\n",
              "             ('following', 102),\n",
              "             ('monday', 51),\n",
              "             ('young', 255),\n",
              "             ('candidates', 51),\n",
              "             ('pains', 51),\n",
              "             ('penalties', 51),\n",
              "             ('stop', 408),\n",
              "             ('embark', 102),\n",
              "             ('related', 51),\n",
              "             ('doing', 51),\n",
              "             ('made', 656),\n",
              "             ('craft', 255),\n",
              "             ('fine', 204),\n",
              "             ('boisterous', 51),\n",
              "             ('everything', 51),\n",
              "             ('connected', 51),\n",
              "             ('famous', 51),\n",
              "             ('amazingly', 51),\n",
              "             ('pleased', 102),\n",
              "             ('late', 357),\n",
              "             ('gradually', 51),\n",
              "             ('monopolising', 51),\n",
              "             ('business', 255),\n",
              "             ('matter', 153),\n",
              "             ('behind', 51),\n",
              "             ('original', 102),\n",
              "             ('tyre', 51),\n",
              "             ('carthage;--the', 51),\n",
              "             ('dead', 255),\n",
              "             ('stranded', 102),\n",
              "             ('aboriginal', 51),\n",
              "             ('whalemen', 51),\n",
              "             ('red', 153),\n",
              "             ('sally', 51),\n",
              "             ('canoes', 51),\n",
              "             ('chase', 51),\n",
              "             ('leviathan', 102),\n",
              "             ('too', 714),\n",
              "             ('adventurous', 51),\n",
              "             ('sloop', 51),\n",
              "             ('forth', 51),\n",
              "             ('partly', 153),\n",
              "             ('laden', 51),\n",
              "             ('imported', 51),\n",
              "             ('cobblestones', 51),\n",
              "             ('throw', 51),\n",
              "             ('whales', 102),\n",
              "             ('discover', 51),\n",
              "             ('risk', 51),\n",
              "             ('harpoon', 255),\n",
              "             ('bowsprit', 51),\n",
              "             ('day', 306),\n",
              "             ('another', 255),\n",
              "             ('ere', 153),\n",
              "             ('destined', 51),\n",
              "             ('port', 51),\n",
              "             ('became', 153),\n",
              "             ('concernment', 51),\n",
              "             ('eat', 51),\n",
              "             ('meanwhile', 153),\n",
              "             ('dubious', 51),\n",
              "             ('nay', 102),\n",
              "             ('dark', 408),\n",
              "             ('dismal', 102),\n",
              "             ('bitingly', 51),\n",
              "             ('cold', 357),\n",
              "             ('cheerless', 51),\n",
              "             ('anxious', 51),\n",
              "             ('grapnels', 51),\n",
              "             ('sounded', 51),\n",
              "             ('pocket', 153),\n",
              "             ('only', 714),\n",
              "             ('brought', 51),\n",
              "             ('pieces', 51),\n",
              "             ('silver,--so', 51),\n",
              "             ('wherever', 102),\n",
              "             ('said', 969),\n",
              "             ('stood', 510),\n",
              "             ('middle', 255),\n",
              "             ('dreary', 102),\n",
              "             ('shouldering', 51),\n",
              "             ('comparing', 51),\n",
              "             ('gloom', 51),\n",
              "             ('darkness', 153),\n",
              "             ('wisdom', 51),\n",
              "             ('conclude', 51),\n",
              "             ('lodge', 51),\n",
              "             ('dear', 51),\n",
              "             ('sure', 255),\n",
              "             ('inquire', 51),\n",
              "             ('price', 51),\n",
              "             ('halting', 51),\n",
              "             ('steps', 51),\n",
              "             ('paced', 51),\n",
              "             ('sign', 306),\n",
              "             ('crossed', 102),\n",
              "             ('harpoons\"--but', 51),\n",
              "             ('looked', 306),\n",
              "             ('expensive', 102),\n",
              "             ('further', 204),\n",
              "             ('bright', 102),\n",
              "             ('windows', 102),\n",
              "             ('fish', 153),\n",
              "             ('inn', 153),\n",
              "             ('fervent', 51),\n",
              "             ('rays', 51),\n",
              "             ('seemed', 816),\n",
              "             ('melted', 51),\n",
              "             ('packed', 102),\n",
              "             ('ice', 204),\n",
              "             ('house', 561),\n",
              "             ('everywhere', 51),\n",
              "             ('congealed', 51),\n",
              "             ('frost', 204),\n",
              "             ('lay', 459),\n",
              "             ('inches', 102),\n",
              "             ...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlWcMA2lYqk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHDU5maCY02n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bb2e0cc-443b-4c42-c56e-f2e7250107de"
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGAPwMDyY8kj",
        "colab_type": "text"
      },
      "source": [
        "## Convert the text sequences into a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzk0nV0qZDAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "sequences = np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtKILhHjZNkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "84584684-2daa-46c0-e3ce-30a08bc170da"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   15,  262, ...,  110,    6,   48],\n",
              "       [  15,  262,    4, ...,    6,   48,    5],\n",
              "       [ 262,    4,   51, ...,   48,    5,  957],\n",
              "       ...,\n",
              "       [  33,  352, 2707, ...,  290,   54,    2],\n",
              "       [ 352, 2707,    1, ...,   54,    2, 2717],\n",
              "       [2707,    1,   68, ...,    2, 2717,   27]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9OuIUafZZhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b52a067-77cc-4989-fa92-285970076a95"
      },
      "source": [
        "sequences.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11602, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSkxTsRUZdnh",
        "colab_type": "text"
      },
      "source": [
        "#### label is the 51st column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXlncvQAZhLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}